### YamlMime:ManagedReference
items:
- uid: System.Speech.Recognition.SpeechRecognitionEngine
  id: SpeechRecognitionEngine
  children:
  - System.Speech.Recognition.SpeechRecognitionEngine.#ctor
  - System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)
  - System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)
  - System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioState
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
  - System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
  - System.Speech.Recognition.SpeechRecognitionEngine.Dispose
  - System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
  - System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
  - System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  - System.Speech.Recognition.SpeechRecognitionEngine.Grammars
  - System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
  - System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers
  - System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
  - System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
  - System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.Recognize
  - System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
  - System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate
  - System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)
  - System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)
  - System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
  - System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
  - System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
  - System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
  - System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars
  - System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)
  - System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)
  langs:
  - csharp
  name: SpeechRecognitionEngine
  nameWithType: SpeechRecognitionEngine
  fullName: System.Speech.Recognition.SpeechRecognitionEngine
  type: Class
  summary: "Предоставляет средства для доступа и управления распознавания речи в процессе."
  remarks: "Для любого из установленных речи распознаватели можно создать экземпляр этого класса. Чтобы получить сведения о том, какие распознаватели установлены, используйте статическое <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>       Этот класс предназначен для запускается речи распознавания ядер для выполнения и обеспечивает управление различными аспектами распознавания речи, следующим образом:: чтобы создать распознавания речи в процессе, используйте один из <xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A>конструкторов.</xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A>      — Для управления грамматики распознавания речи, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A>, и <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A>методов и <xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A>свойство.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>      — Чтобы настроить входные данные для распознавателя, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>, или <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>      — Чтобы выполнить распознавание речи, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>или <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>      — Чтобы изменить способ обработки распознавания бездействия или Непредвиденная входных данных, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, и <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>Свойства.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>      — Чтобы изменить количество вариантов, возвращает распознаватель, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A>свойство.</xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A> Распознаватель возвращает результаты распознавания в <xref:System.Speech.Recognition.RecognitionResult>объекта.</xref:System.Speech.Recognition.RecognitionResult>      — Для синхронизации изменений в распознаватель, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> Распознаватель использует несколько потоков для выполнения задач.      -Для имитации ввода в распознаватель, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>и <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>методы.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>       Объект SpeechRecognitionEngine является исключительно для использования процесса, экземпляр которого создается объект. В отличие от этого, <xref:System.Speech.Recognition.SpeechRecognizer>использует один распознаватель для любого приложения, который хочет воспользоваться им.</xref:System.Speech.Recognition.SpeechRecognizer>      Настроек [!NOTE] настроек вызова всегда <xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A>перед освобождением последней ссылки на распознаватель речи.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A> В противном случае им ресурсы не будут освобождены, пока сборщик мусора вызывает объект распознавателя `Finalize` метод."
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. Because this example uses the `Multiple` mode of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> method, it performs recognition until you close the console window or stop debugging.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (  \n      SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: 'public class SpeechRecognitionEngine : IDisposable'
  inheritance:
  - System.Object
  implements:
  - System.IDisposable
  inheritedMembers: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor
  id: '#ctor'
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionEngine()
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine()
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Инициализирует новый экземпляр <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> класса с помощью распознаватель речи по умолчанию для системы."
  remarks: "До начала распознавания речи распознаватель речи необходимо загрузить хотя бы одну грамматику распознавания и настроить входные данные для распознавателя.       Чтобы загрузить грамматику, вызвать <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>или <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>       Настройка звукового ввода, используйте один из следующих методов:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  syntax:
    content: public SpeechRecognitionEngine ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)
  id: '#ctor(System.Globalization.CultureInfo)'
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionEngine(CultureInfo)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(CultureInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(CultureInfo)
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Инициализирует новый экземпляр <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> класса с помощью распознаватель речи по умолчанию для указанного языкового стандарта."
  remarks: "Microsoft Windows и System.Speech API принять все допустимые коды страны языка. Чтобы выполнить распознавание речи, с помощью языка, заданного параметром `CultureInfo` аргумент, распознавания речи, поддерживающий, что код страны языка должны быть установлены. Распознавания речи, в состав Microsoft Windows 7 работать со следующими кодами языка страны.      -en-GB. Английский (Великобритания) - en US. Английский (США) - de-DE. Немецкий (Германия) - es-ES. Испанский (Испания) - fr-FR. Французский (Франция) - ja-JP. Японский (Япония) - zh-CN. Китайский (Китай) - zh-TW. Также допускаются китайского (Тайвань) двухбуквенный кодов языка, например «en», «fr» или «es».       До начала распознавания распознаватель речи необходимо загрузить грамматику распознавания речи по крайней мере один и настроить входные данные для распознавателя.       Чтобы загрузить грамматику, вызвать <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>или <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>       Настройка звукового ввода, используйте один из следующих методов:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition, and initializes a speech recognizer for the en-US locale.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (  \n      SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public SpeechRecognitionEngine (System.Globalization.CultureInfo culture);
    parameters:
    - id: culture
      type: System.Globalization.CultureInfo
      description: "Языковой стандарт, который должна поддерживать распознаватель речи."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  exceptions:
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "Ни один из установленных речи распознаватели поддерживает указанный языковой стандарт или <code> culture </code> инвариантный язык и региональные параметры."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>Culture</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)
  id: '#ctor(System.Speech.Recognition.RecognizerInfo)'
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionEngine(RecognizerInfo)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(RecognizerInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(RecognizerInfo)
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Инициализирует новый экземпляр <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> с учетом информации <xref href=&quot;System.Speech.Recognition.RecognizerInfo&quot;> </xref> для указания распознаватель для использования."
  remarks: "Для любого из установленных речи распознаватели можно создать экземпляр этого класса. Чтобы получить сведения о том, какие распознаватели установлены, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>       До начала распознавания распознаватель речи необходимо загрузить грамматику распознавания речи по крайней мере один и настроить входные данные для распознавателя.       Чтобы загрузить грамматику, вызвать <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>или <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>       Настройка звукового ввода, используйте один из следующих методов:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition, and initializes a speech recognizer that supports the English language.  \n  \n```c#  \n using System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Select a speech recognizer that supports English.  \n      RecognizerInfo info = null;  \n      foreach (RecognizerInfo ri in SpeechRecognitionEngine.InstalledRecognizers())  \n      {  \n        if (ri.Culture.TwoLetterISOLanguageName.Equals(\"en\"))  \n        {  \n          info = ri;  \n          break;  \n        }  \n      }  \n      if (info == null) return;  \n  \n      // Create the selected recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(info))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public SpeechRecognitionEngine (System.Speech.Recognition.RecognizerInfo recognizerInfo);
    parameters:
    - id: recognizerInfo
      type: System.Speech.Recognition.RecognizerInfo
      description: "Сведения о распознаватель речи конкретных."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)
  id: '#ctor(System.String)'
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionEngine(String)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(String)
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Инициализирует новый экземпляр <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> класса с помощью параметра строка, указывающая имя распознаватель для использования."
  remarks: "Имя токена распознаватель является значение <xref:System.Speech.Recognition.RecognizerInfo.Id%2A>Свойства <xref:System.Speech.Recognition.RecognizerInfo>объект, возвращаемый <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A>свойство распознаватель.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A> </xref:System.Speech.Recognition.RecognizerInfo> </xref:System.Speech.Recognition.RecognizerInfo.Id%2A> Для получения коллекции всех установленных распознавателей, используйте статическое <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>       До начала распознавания распознаватель речи необходимо загрузить грамматику распознавания речи по крайней мере один и настроить входные данные для распознавателя.       Чтобы загрузить грамматику, вызвать <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>или <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>       Настройка звукового ввода, используйте один из следующих методов:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition, and creates an instance of the Speech Recognizer 8.0 for Windows (English - US).  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an instance of the Microsoft Speech Recognizer 8.0 for  \n      // Windows (English - US).  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(\"MS-1033-80-DESK\"))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized += new EventHandler(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public SpeechRecognitionEngine (string recognizerId);
    parameters:
    - id: recognizerId
      type: System.String
      description: "Имя маркера для использования распознавателя речи."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  exceptions:
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "Не распознавания речи с имени маркера установлен, или <code> recognizerId </code> является пустой строкой (»»)."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>recognizerId</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
  id: AudioFormat
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioFormat
  nameWithType: SpeechRecognitionEngine.AudioFormat
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Получает формат аудио, полученных <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "Настройка звукового ввода, используйте один из следующих методов:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  example:
  - "The example below uses AudioFormat to obtain and display audio format data.  \n  \n```  \nstatic void DisplayAudioDeviceFormat(Label label, SpeechRecognitionEngine recognitionEngine)   \n{  \n  \n  if (recognitionEngine != null && label != null)   \n  {  \n    label.Text = String.Format(\"Encoding Format:         {0}\\n\" +  \n          \"AverageBytesPerSecond    {1}\\n\" +  \n          \"BitsPerSample            {2}\\n\" +  \n          \"BlockAlign               {3}\\n\" +  \n          \"ChannelCount             {4}\\n\" +  \n          \"SamplesPerSecond         {5}\",  \n          recognitionEngine.AudioFormat.EncodingFormat.ToString(),  \n          recognitionEngine.AudioFormat.AverageBytesPerSecond,  \n          recognitionEngine.AudioFormat.BitsPerSample,  \n          recognitionEngine.AudioFormat.BlockAlign,  \n          recognitionEngine.AudioFormat.ChannelCount,  \n          recognitionEngine.AudioFormat.SamplesPerSecond);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat { get; }
    return:
      type: System.Speech.AudioFormat.SpeechAudioFormatInfo
      description: "Формат аудио во входных данных для <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> экземпляра, или <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> Если входные данные не задана, или значение null ввод."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
  id: AudioLevel
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioLevel
  nameWithType: SpeechRecognitionEngine.AudioLevel
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возвращает уровень аудио, полученных <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "Значение 0 представляет бездействия, а максимальный уровень представляет 100."
  syntax:
    content: public int AudioLevel { get; }
    return:
      type: System.Int32
      description: "Уровень аудио входных данных для распознавания речи, от 0 до 100."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
  id: AudioLevelUpdated
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioLevelUpdated
  nameWithType: SpeechRecognitionEngine.AudioLevelUpdated
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возникает, когда <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> сообщает уровень аудио входных данных."
  remarks: "<xref:System.Speech.Recognition.SpeechRecognitionEngine>Вызывает это событие несколько раз в секунду.</xref:System.Speech.Recognition.SpeechRecognitionEngine> Частота, с помощью которого возникает событие зависит от компьютера, на котором выполняется приложение.       Чтобы получить уровень аудио во время события, используйте <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A>Свойства связанного <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>.</xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs> </xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A> Чтобы получить текущий уровень аудио входных данных для распознавателя, используйте распознавателя <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A>свойство.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A>       При создании делегата AudioLevelUpdated, необходимо указать метод, обрабатывающий событие. Чтобы связать событие с обработчиком событий, добавьте в событие экземпляр делегата. Обработчик событий вызывается всякий раз, когда происходит событие, пока не будет удален делегат. Дополнительные сведения о делегатах-обработчиках событий см. в разделе [события и делегаты](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example adds a handler for the AudioLevelUpdated event to a <xref:System.Speech.Recognition.SpeechRecognitionEngine> object. The handler outputs the new audio level to the console.  \n  \n```  \nprivate SpeechRecognitionEngine recognizer;  \n  \n// Initialize the SpeechRecognitionEngine object.   \nprivate void Initialize()  \n{  \n  recognizer = new SpeechRecognitionEngine();  \n  \n  // Add an event handler for the AudioLevelUpdated event.  \n  recognizer.AudioLevelUpdated +=   \n   new EventHandler<AudioLevelUpdatedEventArgs>(recognizer_AudioLevelUpdated);  \n  \n  // Add other initialization code here.  \n  \n}  \n  \n// Write the audio level to the console when the AudioLevelUpdated event is raised.  \nvoid recognizer_AudioLevelUpdated(object sender, AudioLevelUpdatedEventArgs e)  \n{  \n  Console.WriteLine(\"The audio level is now: {0}.\", e.AudioLevel);  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs> AudioLevelUpdated;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioLevelUpdatedEventArgs}
      description: "Для добавления."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
  id: AudioPosition
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioPosition
  nameWithType: SpeechRecognitionEngine.AudioPosition
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Получает текущее расположение в аудиопоток, формируемых устройство, которое предоставляет входные данные для <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "Свойство AudioPosition ссылается на позицию устройство ввода в созданный аудиопотока. В отличие от этого <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>свойство ссылается на позицию распознавателя внутри его аудио входных данных.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> Эти позиции могут быть разными. Например, если распознаватель получила ввода, для которого он не еще создан результатов распознавания, то значение <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>свойства меньше, чем значение свойства AudioPosition.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>"
  example:
  - "In the following example, the in-process speech recognizer uses a dictation grammar to match speech input. A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> event writes to the console the AudioPosition, <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>, and  <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A> when the speech recognizer detects speech at its input.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognitionEngine recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognition engine for US English.  \n      using (recognizer = new SpeechRecognitionEngine(  \n        new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Create a grammar for finding services in different cities.  \n        Choices services = new Choices(new string[] { \"restaurants\", \"hotels\", \"gas stations\" });  \n        Choices cities = new Choices(new string[] { \"Seattle\", \"Boston\", \"Dallas\" });  \n  \n        GrammarBuilder findServices = new GrammarBuilder(\"Find\");  \n        findServices.Append(services);  \n        findServices.Append(\"near\");  \n        findServices.Append(cities);  \n  \n        // Create a Grammar object from the GrammarBuilder and load it to the recognizer.  \n        Grammar servicesGrammar = new Grammar(findServices);  \n        recognizer.LoadGrammarAsync(servicesGrammar);  \n  \n        // Add handlers for events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  \n  \n        // Start asynchronous recognition.  \n        recognizer.RecognizeAsync();  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Gather information about detected speech and write it to the console.  \n    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Speech detected:\");  \n      Console.WriteLine(\"  Audio level: \" + recognizer.AudioLevel);  \n      Console.WriteLine(\"  Audio position at the event: \" + e.AudioPosition);  \n      Console.WriteLine(\"  Current audio position: \" + recognizer.AudioPosition);  \n      Console.WriteLine(\"  Current recognizer audio position: \" +   \n        recognizer.RecognizerAudioPosition);  \n    }  \n  \n    // Write the text of the recognition result to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"\\nSpeech recognized: \" + e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public TimeSpan AudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "Текущее расположение в аудиопоток, формируемых устройство ввода."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
  id: AudioSignalProblemOccurred
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioSignalProblemOccurred
  nameWithType: SpeechRecognitionEngine.AudioSignalProblemOccurred
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возникает, когда <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> обнаружена проблема в звуковых сигналов."
  remarks: "Чтобы получить которых ошибка, используйте <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A>свойство связанного <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>.</xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs> </xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A>       При создании делегата AudioSignalProblemOccurred, необходимо указать метод, обрабатывающий событие. Чтобы связать событие с обработчиком событий, добавьте в событие экземпляр делегата. Обработчик событий вызывается всякий раз, когда происходит событие, пока не будет удален делегат. Дополнительные сведения о делегатах-обработчиках событий см. в разделе [события и делегаты](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example defines an event handler that gathers information about an AudioSignalProblemOccurred event.  \n  \n```  \nprivate SpeechRecognitionEngine recognizer;  \n  \n// Initialize the speech recognition engine.  \nprivate void Initialize()  \n{  \n  recognizer = new SpeechRecognitionEngine();  \n  \n  // Add a handler for the AudioSignalProblemOccurred event.  \n  recognizer.AudioSignalProblemOccurred +=   \n    new EventHandler<AudioSignalProblemOccurredEventArgs>(  \n      recognizer_AudioSignalProblemOccurred);  \n}  \n  \n// Gather information when the AudioSignalProblemOccurred event is raised.  \nvoid recognizer_AudioSignalProblemOccurred(object sender, AudioSignalProblemOccurredEventArgs e)  \n{  \n  StringBuilder details = new StringBuilder();  \n  \n  details.AppendLine(\"Audio signal problem information:\");  \n  details.AppendFormat(  \n    \" Audio level:               {0}\" + Environment.NewLine +  \n    \" Audio position:            {1}\" + Environment.NewLine +  \n    \" Audio signal problem:      {2}\" + Environment.NewLine +  \n    \" Recognition engine audio position: {3}\" + Environment.NewLine,  \n    e.AudioLevel, e.AudioPosition,  e.AudioSignalProblem,  \n    e.recoEngineAudioPosition);  \n  \n  // Insert additional event handler code here.  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs> AudioSignalProblemOccurred;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioSignalProblemOccurredEventArgs}
      description: "Для добавления."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioState
  id: AudioState
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioState
  nameWithType: SpeechRecognitionEngine.AudioState
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioState
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Получает состояние аудио, полученных <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "Свойство AudioState представляет состояние звуковых с членом <xref:System.Speech.Recognition.AudioState>перечисления.</xref:System.Speech.Recognition.AudioState>"
  syntax:
    content: public System.Speech.Recognition.AudioState AudioState { get; }
    return:
      type: System.Speech.Recognition.AudioState
      description: "Состояние аудио входных данных для распознавания речи."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.AudioState*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
  id: AudioStateChanged
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioStateChanged
  nameWithType: SpeechRecognitionEngine.AudioStateChanged
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возникает, когда изменения состояния в аудио, полученных <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "Чтобы получить состояние звуковых во время события, используйте <xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A>свойство связанного <xref:System.Speech.Recognition.AudioStateChangedEventArgs>.</xref:System.Speech.Recognition.AudioStateChangedEventArgs> </xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> Чтобы получить текущее состояние аудио входных данных для распознавателя, используйте распознавателя <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A>свойство.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A> Дополнительные сведения о состоянии аудио см. в разделе <xref:System.Speech.Recognition.AudioState>перечисления.</xref:System.Speech.Recognition.AudioState>       При создании делегата AudioStateChanged, необходимо указать метод, обрабатывающий событие. Чтобы связать событие с обработчиком событий, добавьте в событие экземпляр делегата. Обработчик событий вызывается всякий раз, когда происходит событие, пока не будет удален делегат. Дополнительные сведения о делегатах-обработчиках событий см. в разделе [события и делегаты](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example uses a handler for the AudioStateChanged event to write the recognizer's new <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A> to the console each time it changes, using a member of the <xref:System.Speech.Recognition.AudioState> enumeration.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a grammar.  \n        Choices animals = new Choices(new string[] { \"cow\", \"pig\", \"goat\" });  \n        GrammarBuilder farm = new GrammarBuilder(\"On this farm he had a\");  \n        farm.Append(animals);  \n        Grammar farmAnimals = new Grammar(farm);  \n        farmAnimals.Name = \"Farm\";  \n        recognizer.LoadGrammar(farmAnimals);  \n  \n        // Attach event handlers.  \n        recognizer.AudioStateChanged +=  \n          new EventHandler<AudioStateChangedEventArgs>(recognizer_AudioStateChanged);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null && e.Result.Text != null)  \n      {  \n        Console.WriteLine();  \n        Console.WriteLine(\"  Recognized text =  {0}\", e.Result.Text);  \n        Console.WriteLine();  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  Recognized text not available.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Done.\");  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the AudioStateChanged event.  \n    static void recognizer_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  \n    {  \n      Console.WriteLine(\"The new audio state is: \" + e.AudioState);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs> AudioStateChanged;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioStateChangedEventArgs}
      description: "Для добавления."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
  id: BabbleTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: BabbleTimeout
  nameWithType: SpeechRecognitionEngine.BabbleTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возвращает или задает промежуток времени, в течение которого <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> принимает входной содержащего только фоновых шумов, перед окончательным утверждением распознавания."
  remarks: "Каждый распознаватель речи использует алгоритм для различения бездействия и речи. Распознаватель классифицируются как фоновых шумов любой не бездействия ввода, не соответствует первоначальной правило любого распознавателя загружены и включены грамматики распознавания речи. Если распознаватель получает только фоновых шумов и бездействия в течение интервала времени ожидания babble, распознаватель завершает операции распознавания.      -Для распознавания асинхронных операций, вызывает распознаватель <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>событий, где <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=fullName>свойство `true`и <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName>свойство `null`.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>      — Для распознавания синхронной операции и эмуляции, возвращает распознаватель `null`, вместо допустимым <xref:System.Speech.Recognition.RecognitionResult>.</xref:System.Speech.Recognition.RecognitionResult>       Если время ожидания babble имеет значение 0, распознаватель не выполняет проверку babble время ожидания. Интервал времени ожидания может быть любым положительным значением. Значение по умолчанию — 0 секунд."
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition that sets the BabbleTimeout and <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> before initiating speech recognition. Handlers for the speech recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> events output event information to the console to demonstrate how the <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> affect recognition operations.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        // Load a Grammar object.  \n        recognizer.LoadGrammar(CreateServicesGrammar(\"FindServices\"));  \n  \n        // Add event handlers.  \n        recognizer.AudioStateChanged +=  \n          new EventHandler<AudioStateChangedEventArgs>(  \n            AudioStateChangedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(3);  \n        recognizer.BabbleTimeout = TimeSpan.FromSeconds(2);  \n        recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1);  \n        recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.5);  \n  \n        Console.WriteLine(\"BabbleTimeout: {0}\", recognizer.BabbleTimeout);  \n        Console.WriteLine(\"InitialSilenceTimeout: {0}\", recognizer.InitialSilenceTimeout);  \n        Console.WriteLine(\"EndSilenceTimeout: {0}\", recognizer.EndSilenceTimeout);  \n        Console.WriteLine(\"EndSilenceTimeoutAmbiguous: {0}\", recognizer.EndSilenceTimeoutAmbiguous);  \n        Console.WriteLine();  \n  \n        // Start asynchronous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Single);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Create a grammar and build it into a Grammar object.   \n    static Grammar CreateServicesGrammar(string grammarName)  \n    {  \n  \n      // Create a grammar for finding services in different cities.  \n      Choices services = new Choices(new string[] { \"restaurants\", \"hotels\", \"gas stations\" });  \n      Choices cities = new Choices(new string[] { \"Seattle\", \"Boston\", \"Dallas\" });  \n  \n      GrammarBuilder findServices = new GrammarBuilder(\"Find\");  \n      findServices.Append(services);  \n      findServices.Append(\"near\");  \n      findServices.Append(cities);  \n  \n      // Create a Grammar object from the GrammarBuilder..  \n      Grammar servicesGrammar = new Grammar(findServices);  \n      servicesGrammar.Name = (\"FindServices\");  \n      return servicesGrammar;  \n    }  \n  \n    // Handle the AudioStateChanged event.  \n    static void AudioStateChangedHandler(  \n      object sender, AudioStateChangedEventArgs e)  \n    {  \n      Console.WriteLine(\"AudioStateChanged ({0}): {1}\",  \n        DateTime.Now.ToString(\"mm:ss.f\"), e.AudioState);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"RecognizeCompleted ({0}):\",  \n        DateTime.Now.ToString(\"mm:ss.f\"));  \n  \n      string resultText;  \n      if (e.Result != null) { resultText = e.Result.Text; }  \n      else { resultText = \"<null>\"; }  \n  \n      Console.WriteLine(  \n        \" BabbleTimeout: {0}; InitialSilenceTimeout: {1}; Result text: {2}\",  \n        e.BabbleTimeout, e.InitialSilenceTimeout, resultText);  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\" Exception message: \", e.Error.Message);  \n      }  \n  \n      // Start the next asynchronous recognition operation.  \n      ((SpeechRecognitionEngine)sender).RecognizeAsync(RecognizeMode.Single);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public TimeSpan BabbleTimeout { get; set; }
    return:
      type: System.TimeSpan
      description: "Длительность интервала времени."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "Это свойство имеет значение меньше 0 секунд."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose
  id: Dispose
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Dispose()
  nameWithType: SpeechRecognitionEngine.Dispose()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Dispose()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Удаляет <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> объекта."
  syntax:
    content: public void Dispose ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Dispose*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)
  id: Dispose(System.Boolean)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Dispose(Boolean)
  nameWithType: SpeechRecognitionEngine.Dispose(Boolean)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Dispose(Boolean)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Удаляет <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> объекта и выпусках ресурсы, используемые во время сеанса."
  syntax:
    content: protected virtual void Dispose (bool disposing);
    parameters:
    - id: disposing
      type: System.Boolean
      description: "<xref uid=&quot;langword_csharp_true&quot; name=&quot;true&quot; href=&quot;&quot;></xref>для освобождения управляемых и неуправляемых ресурсов; <xref uid=&quot;langword_csharp_false&quot; name=&quot;false&quot; href=&quot;&quot;> </xref> для освобождения только неуправляемых ресурсов."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Dispose*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)
  id: EmulateRecognize(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognize(String)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Имитирует входных данных фразы для распознавания речи, с помощью текста вместо аудио для распознавания речи синхронной."
  remarks: "Вызывает распознавателя речи <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, и <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>события как если бы операции распознавания не эмулируется.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>       Распознаваемых Vista и Windows 7 без учета регистра и символов ширину при применении правил грамматики ввода фразы. Дополнительные сведения об этом типе сравнения см. в <xref:System.Globalization.CompareOptions>перечислении значений <xref:System.Globalization.CompareOptions>и <xref:System.Globalization.CompareOptions>.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> Распознаватели также пропустить символы новой строки и лишние пробелы и обрабатывать знаки пунктуации как литерал входных данных."
  example:
  - "The code example below is part of a console application that demonstrates emulated input, the associated recognition results, and the associated events raised by the speech recognizer. The example generates the following output.  \n  \n```  \nTestRecognize(\"Smith\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Smith; Text = Smith  \n...Recognition result text = Smith  \n  \nTestRecognize(\"Jones\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Jones; Text = Jones  \n...Recognition result text = Jones  \n  \nTestRecognize(\"Mister\")...  \n SpeechDetected event raised.  \n SpeechHypothesized event raised.  \n  Grammar = Smith; Text = mister  \n SpeechRecognitionRejected event raised.  \n  Grammar = <not available>; Text =  \n...No recognition result.  \n  \nTestRecognize(\"Mister Smith\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Smith; Text = mister Smith  \n...Recognition result text = mister Smith  \n  \npress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace Sre_EmulateRecognize  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n  \n        // Load grammars.  \n        recognizer.LoadGrammar(CreateNameGrammar(\"Smith\"));  \n        recognizer.LoadGrammar(CreateNameGrammar(\"Jones\"));  \n  \n        // Disable audio input to the recognizer.  \n        recognizer.SetInputToNull();  \n  \n        // Add handlers for events raised by the EmulateRecognize method.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n  \n        // Start four synchronous emulated recognition operations.  \n        TestRecognize(recognizer, \"Smith\");  \n        TestRecognize(recognizer, \"Jones\");  \n        TestRecognize(recognizer, \"Mister\");  \n        TestRecognize(recognizer, \"Mister Smith\");  \n      }  \n  \n      Console.WriteLine(\"press any key to exit...\");  \n      Console.ReadKey(true);  \n    }  \n  \n    // Create a simple name grammar.  \n    // Set the grammar name to the surname.  \n    private static Grammar CreateNameGrammar(string surname)  \n    {  \n      GrammarBuilder builder = new GrammarBuilder(\"mister\", 0, 1);  \n      builder.Append(surname);  \n  \n      Grammar nameGrammar = new Grammar(builder);  \n      nameGrammar.Name = surname;  \n  \n      return nameGrammar;  \n    }  \n  \n    // Send emulated input to the recognizer for synchronous recognition.  \n    private static void TestRecognize(  \n      SpeechRecognitionEngine recognizer, string input)  \n    {  \n      Console.WriteLine(\"TestRecognize(\\\"{0}\\\")...\", input);  \n      RecognitionResult result =  \n        recognizer.EmulateRecognize(input,CompareOptions.IgnoreCase);  \n      if (result != null)  \n      {  \n        Console.WriteLine(\"...Recognition result text = {0}\",  \n          result.Text ?? \"<null>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"...No recognition result.\");  \n      }  \n      Console.WriteLine();  \n    }  \n  \n    static void SpeechDetectedHandler(  \n      object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechDetected event raised.\");  \n    }  \n  \n    // Handle events.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechHypothesized event raised.\");  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechRecognitionRejected event raised.\");  \n      if (e.Result != null)  \n      {  \n        string grammarName;  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name ?? \"<none>\";  \n        }  \n        else  \n        {  \n          grammarName = \"<not available>\";  \n        }  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          grammarName, e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechRecognized event raised.\");  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText);
    parameters:
    - id: inputText
      type: System.String
      description: "Входные данные для операции распознавания."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "Результат для операции распознавания, или <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> , если операция не завершена или распознаватель не включен."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "Распознаватель был загружен распознавания грамматики не речи система."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>inputText</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>inputText</code>является пустой строкой (»»)."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  id: EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Имитирует входных данных конкретных слов для распознавания речи, с помощью текста вместо аудио для распознавания речи синхронный и определяет способ обработки Юникода сравнение слова и грамматики распознавания речи загружена в распознаватель."
  remarks: "Вызывает распознавателя речи <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, и <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>события как если бы операции распознавания не эмулируется.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>       Использует распознаватель `compareOptions` случае применения правилам грамматики для ввода фразы. Распознаваемых Vista и Windows 7 не учитывать регистр при <xref:System.Globalization.CompareOptions>или <xref:System.Globalization.CompareOptions>будет присутствовать.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> Распознаватель никогда не учитывает ширину символа и никогда не игнорирует тип японской азбуки. Распознаватель также игнорирует символы новой строки и лишние пробелы и обрабатывает знаки пунктуации как литерал входных данных. Дополнительные сведения о ширины символов и типа японской азбуки. в разделе <xref:System.Globalization.CompareOptions>перечисления.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: wordUnits
      type: System.Speech.Recognition.RecognizedWordUnit[]
      description: "Массив единиц word, содержащий входные данные для операции распознавания."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "Побитовое сочетание значений перечисления, описывающие тип сравнения, используемый для распознавания эмулированной операции."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "Результат для операции распознавания, или <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> , если операция не завершена или распознаватель не включен."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "Распознаватель был загружен распознавания грамматики не речи система."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>wordUnits</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>wordUnits</code>содержит один или несколько <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> элементов."
  - type: System.NotSupportedException
    commentId: T:System.NotSupportedException
    description: "<code>compareOptions</code>содержит <xref:System.Globalization.CompareOptions>, <xref:System.Globalization.CompareOptions>, или <xref:System.Globalization.CompareOptions> флаг."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  id: EmulateRecognize(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognize(String,CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(String,CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Имитирует входных данных фразы для распознавания речи, с помощью текста вместо аудио для распознавания речи синхронный и определяет сравнение Юникода фразы и распознавания грамматики загруженного речи при обработке распознавателя."
  remarks: "Вызывает распознавателя речи <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, и <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>события как если бы операции распознавания не эмулируется.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>       Использует распознаватель `compareOptions` случае применения правилам грамматики для ввода фразы. Распознаваемых Vista и Windows 7 не учитывать регистр при <xref:System.Globalization.CompareOptions>или <xref:System.Globalization.CompareOptions>будет присутствовать.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> Распознаватель никогда не учитывает ширину символа и никогда не игнорирует тип японской азбуки. Распознаватель также игнорирует символы новой строки и лишние пробелы и обрабатывает знаки пунктуации как литерал входных данных. Дополнительные сведения о ширины символов и типа японской азбуки. в разделе <xref:System.Globalization.CompareOptions>перечисления.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: inputText
      type: System.String
      description: "Фраза ввода для операции распознавания."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "Побитовое сочетание значений перечисления, описывающие тип сравнения, используемый для распознавания эмулированной операции."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "Результат для операции распознавания, или <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> , если операция не завершена или распознаватель не включен."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "Распознаватель был загружен распознавания грамматики не речи система."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>inputText</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>inputText</code>является пустой строкой (»»)."
  - type: System.NotSupportedException
    commentId: T:System.NotSupportedException
    description: "<code>compareOptions</code>содержит <xref:System.Globalization.CompareOptions>, <xref:System.Globalization.CompareOptions>, или <xref:System.Globalization.CompareOptions> флаг."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)
  id: EmulateRecognizeAsync(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognizeAsync(String)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Имитирует входных данных фразы для распознавания речи, с помощью текста вместо аудио для распознавания речи асинхронной."
  remarks: "Вызывает распознавателя речи <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, и <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>события как если бы операции распознавания не эмулируется.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> По завершении операции асинхронной распознавания распознаватель вызывает <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>событий.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>       Распознаваемых Vista и Windows 7 без учета регистра и символов ширину при применении правил грамматики ввода фразы. Дополнительные сведения об этом типе сравнения см. в <xref:System.Globalization.CompareOptions>перечислении значений <xref:System.Globalization.CompareOptions>и <xref:System.Globalization.CompareOptions>.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> Распознаватели также пропустить символы новой строки и лишние пробелы и обрабатывать знаки пунктуации как литерал входных данных."
  example:
  - "The code example below is part of a console application that demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. The example generates the following output.  \n  \n```  \n  \nTestRecognizeAsync(\"Smith\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Smith; Text = Smith  \n EmulateRecognizeCompleted event raised.  \n  Grammar = Smith; Text = Smith  \n Done.  \n  \nTestRecognizeAsync(\"Jones\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Jones; Text = Jones  \n EmulateRecognizeCompleted event raised.  \n  Grammar = Jones; Text = Jones  \n Done.  \n  \nTestRecognizeAsync(\"Mister\")...  \n SpeechDetected event raised.  \n SpeechHypothesized event raised.  \n  Grammar = Smith; Text = mister  \n SpeechRecognitionRejected event raised.  \n  Grammar = <not available>; Text =  \n EmulateRecognizeCompleted event raised.  \n  No recognition result available.  \n Done.  \n  \nTestRecognizeAsync(\"Mister Smith\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Smith; Text = mister Smith  \n EmulateRecognizeCompleted event raised.  \n  Grammar = Smith; Text = mister Smith  \n Done.  \n  \npress any key to exit...  \n```  \n  \n```c#  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SreEmulateRecognizeAsync  \n{  \n  class Program  \n  {  \n    // Indicate when an asynchronous operation is finished.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Load grammars.  \n        recognizer.LoadGrammar(CreateNameGrammar(\"Smith\"));  \n        recognizer.LoadGrammar(CreateNameGrammar(\"Jones\"));  \n  \n        // Configure the audio input.  \n        recognizer.SetInputToNull();  \n  \n        // Add event handlers for the events raised by the  \n        // EmulateRecognizeAsync method.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHander);  \n  \n        // Start four asynchronous emulated recognition operations.  \n        TestRecognizeAsync(recognizer, \"Smith\");  \n        TestRecognizeAsync(recognizer, \"Jones\");  \n        TestRecognizeAsync(recognizer, \"Mister\");  \n        TestRecognizeAsync(recognizer, \"Mister Smith\");  \n      }  \n  \n      Console.WriteLine(\"press any key to exit...\");  \n      Console.ReadKey(true);  \n    }  \n  \n    // Create a simple name grammar.  \n    // Set the grammar name to the surname.  \n    private static Grammar CreateNameGrammar(string surname)  \n    {  \n      GrammarBuilder builder = new GrammarBuilder(\"mister\", 0, 1);  \n      builder.Append(surname);  \n  \n      Grammar nameGrammar = new Grammar(builder);  \n      nameGrammar.Name = surname;  \n  \n      return nameGrammar;  \n    }  \n  \n    // Send emulated input to the recognizer for asynchronous  \n    // recognition.  \n    private static void TestRecognizeAsync(  \n      SpeechRecognitionEngine recognizer, string input)  \n    {  \n      completed = false;  \n  \n      Console.WriteLine(\"TestRecognizeAsync(\\\"{0}\\\")...\", input);  \n      recognizer.EmulateRecognizeAsync(input);  \n  \n      // Wait for the operation to complete.  \n      while (!completed)  \n      {  \n        Thread.Sleep(333);  \n      }  \n  \n      Console.WriteLine(\" Done.\");  \n      Console.WriteLine();  \n    }  \n  \n    static void SpeechDetectedHandler(  \n      object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechDetected event raised.\");  \n    }  \n  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechHypothesized event raised.\");  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    // Handle events.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechRecognitionRejected event raised.\");  \n      if (e.Result != null)  \n      {  \n        string grammarName;  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name ?? \"<none>\";  \n        }  \n        else  \n        {  \n          grammarName = \"<not available>\";  \n        }  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          grammarName, e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechRecognized event raised.\");  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text );  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    static void EmulateRecognizeCompletedHander(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" EmulateRecognizeCompleted event raised.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"  {0} exception encountered: {1}:\",  \n          e.Error.GetType().Name, e.Error.Message);  \n      }  \n      else if (e.Cancelled)  \n      {  \n        Console.WriteLine(\"  Operation cancelled.\");  \n      }  \n      else if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void EmulateRecognizeAsync (string inputText);
    parameters:
    - id: inputText
      type: System.String
      description: "Входные данные для операции распознавания."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "Распознаватель был загружен распознавания грамматики не речи система или распознаватель имеет распознавания асинхронную операцию, которая еще не завершена."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>inputText</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>inputText</code>является пустой строкой (»»)."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  id: EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Имитирует входных данных конкретных слов для распознавания речи, используя массив <xref href=&quot;System.Speech.Recognition.RecognizedWordUnit&quot;> </xref> объектов вместо аудио для распознавания речи асинхронных и указывает, как распознаватель обрабатывает сравнение Юникода слова и грамматики распознавания речи загружена."
  remarks: "Вызывает распознавателя речи <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, и <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>события как если бы операции распознавания не эмулируется.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> По завершении операции асинхронной распознавания распознаватель вызывает <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>событий.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>       Использует распознаватель `compareOptions` случае применения правилам грамматики для ввода фразы. Распознаваемых Vista и Windows 7 не учитывать регистр при <xref:System.Globalization.CompareOptions>или <xref:System.Globalization.CompareOptions>будет присутствовать.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> Распознаватель всегда игнорировать ширину символа и никогда не игнорируется тип японской азбуки. Распознаватели также пропустить символы новой строки и лишние пробелы и обрабатывать знаки пунктуации как литерал входных данных. Дополнительные сведения о ширины символов и типа японской азбуки. в разделе <xref:System.Globalization.CompareOptions>перечисления.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public void EmulateRecognizeAsync (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: wordUnits
      type: System.Speech.Recognition.RecognizedWordUnit[]
      description: "Массив единиц word, содержащий входные данные для операции распознавания."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "Побитовое сочетание значений перечисления, описывающие тип сравнения, используемый для распознавания эмулированной операции."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "Распознаватель был загружен распознавания грамматики не речи система или распознаватель имеет распознавания асинхронную операцию, которая еще не завершена."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>wordUnits</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>wordUnits</code>содержит один или несколько <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> элементов."
  - type: System.NotSupportedException
    commentId: T:System.NotSupportedException
    description: "<code>compareOptions</code>содержит <xref:System.Globalization.CompareOptions>, <xref:System.Globalization.CompareOptions>, или <xref:System.Globalization.CompareOptions> флаг."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  id: EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognizeAsync(String,CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(String,CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Имитирует входных данных фразы для распознавания речи, с помощью текста вместо аудио для распознавания речи асинхронной и определяет способ обработки Юникода сравнение фразы и грамматики распознавания речи загружена в распознаватель."
  remarks: "Вызывает распознавателя речи <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, и <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>события как если бы операции распознавания не эмулируется.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> По завершении операции асинхронной распознавания распознаватель вызывает <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>событий.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>       Использует распознаватель `compareOptions` случае применения правилам грамматики для ввода фразы. Распознаваемых Vista и Windows 7 не учитывать регистр при <xref:System.Globalization.CompareOptions>или <xref:System.Globalization.CompareOptions>будет присутствовать.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> Распознаватель всегда игнорировать ширину символа и никогда не игнорируется тип японской азбуки. Распознаватели также пропустить символы новой строки и лишние пробелы и обрабатывать знаки пунктуации как литерал входных данных. Дополнительные сведения о ширины символов и типа японской азбуки. в разделе <xref:System.Globalization.CompareOptions>перечисления.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public void EmulateRecognizeAsync (string inputText, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: inputText
      type: System.String
      description: "Фраза ввода для операции распознавания."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "Побитовое сочетание значений перечисления, описывающие тип сравнения, используемый для распознавания эмулированной операции."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "Распознаватель был загружен распознавания грамматики не речи система или распознаватель имеет распознавания асинхронную операцию, которая еще не завершена."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>inputText</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>inputText</code>является пустой строкой (»»)."
  - type: System.NotSupportedException
    commentId: T:System.NotSupportedException
    description: "<code>compareOptions</code>содержит <xref:System.Globalization.CompareOptions>, <xref:System.Globalization.CompareOptions>, или <xref:System.Globalization.CompareOptions> флаг."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
  id: EmulateRecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognizeCompleted
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возникает, когда <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> завершает операцию асинхронного распознавания эмулированной входных данных."
  remarks: "Каждый <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>метод начинает операцию асинхронного распознавания.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> <xref:System.Speech.Recognition.SpeechRecognitionEngine>Вызывает событие EmulateRecognizeCompleted, когда он завершает асинхронную операцию.</xref:System.Speech.Recognition.SpeechRecognitionEngine>       <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>Операции могут вызывать <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, и <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>события.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> EmulateRecognizeCompleted событий — последний такого события, что распознаватель создает для данной операции.       При успешном выполнении эмулированной распознавания доступен результат распознавания, используя одно из следующих: - <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A>Свойства <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>объекта в обработчик события EmulateRecognizeCompleted.</xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs> </xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A>      - <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>Свойства <xref:System.Speech.Recognition.SpeechRecognizedEventArgs>объекта в обработчике <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>событий.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognizedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>       Если эмулированной распознавания не выполнена, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>событие не происходит и <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A>будет иметь значение null.</xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>       <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>является производным от <xref:System.ComponentModel.AsyncCompletedEventArgs>.</xref:System.ComponentModel.AsyncCompletedEventArgs></xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>       <xref:System.Speech.Recognition.SpeechRecognizedEventArgs>является производным от <xref:System.Speech.Recognition.RecognitionEventArgs>.</xref:System.Speech.Recognition.RecognitionEventArgs></xref:System.Speech.Recognition.SpeechRecognizedEventArgs>       При создании делегата EmulateRecognizeCompleted, необходимо указать метод, обрабатывающий событие. Чтобы связать событие с обработчиком событий, добавьте в событие экземпляр делегата. Обработчик событий вызывается всякий раз, когда происходит событие, пока не будет удален делегат. Дополнительные сведения о делегатах-обработчиках событий см. в разделе [события и делегаты](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace InProcessRecognizer  \n{  \n  class Program  \n  {  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an instance of an in-process recognizer.  \n      using (SpeechRecognitionEngine recognizer =   \n        new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call mathches the grammar  \n        // and generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call does not match the grammar  \n        // or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Result of 1st call to EmulateRecognizeAsync = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n        Console.WriteLine();  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the EmulateRecognizeCompleted event.  \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"Result of 2nd call to EmulateRecognizeAsync = No result generated.\");  \n      }  \n  \n      // Indicate the asynchronous operation is complete.  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs> EmulateRecognizeCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.EmulateRecognizeCompletedEventArgs}
      description: "Для добавления."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
  id: EndSilenceTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EndSilenceTimeout
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возвращает или задает интервал бездействия, <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> будет принимать в конце однозначным входные данные перед завершением операции распознавания."
  remarks: "Распознаватель речи использует этот интервал времени ожидания при однозначном распознавания входных данных. Например, для грамматики распознавания речи, который поддерживает распознавание любого» новый игры обратитесь» или «новая игра»» новый игры обратитесь» является однозначным входом и «новая игра» является неоднозначным входными данными.       Это свойство определяет время ожидания распознавания речи для дополнительных входных данных перед окончательным утверждением операции распознавания. Интервал времени ожидания может составлять от 0 секунд до 10 секунд включительно. Значение по умолчанию — 150 миллисекунд.       Чтобы задать интервал времени ожидания для неоднозначных входных данных, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>свойство.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>"
  syntax:
    content: public TimeSpan EndSilenceTimeout { get; set; }
    return:
      type: System.TimeSpan
      description: "Длительность периода бездействия."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "Это свойство имеет значение меньше 0 секунд или больше 10 секунд."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  id: EndSilenceTimeoutAmbiguous
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EndSilenceTimeoutAmbiguous
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возвращает или задает интервал бездействия, <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> принять в конце неоднозначных входных данных перед завершением операции распознавания."
  remarks: "Распознаватель речи использует этот интервал времени ожидания при распознавания ввода является неоднозначным. Например, для грамматики распознавания речи, который поддерживает распознавание любого» новый игры обратитесь» или «новая игра»» новый игры обратитесь» является однозначным входом и «новая игра» является неоднозначным входными данными.       Это свойство определяет время ожидания распознавания речи для дополнительных входных данных перед окончательным утверждением операции распознавания. Интервал времени ожидания может составлять от 0 секунд до 10 секунд включительно. Значение по умолчанию — 500 миллисекунд.       Чтобы задать интервал времени ожидания для однозначных входных данных, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>свойство.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>"
  syntax:
    content: public TimeSpan EndSilenceTimeoutAmbiguous { get; set; }
    return:
      type: System.TimeSpan
      description: "Длительность периода бездействия."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "Это свойство имеет значение меньше 0 секунд или больше 10 секунд."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Grammars
  id: Grammars
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Grammars
  nameWithType: SpeechRecognitionEngine.Grammars
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Grammars
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возвращает коллекцию <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> объекты, находящиеся в этом <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> экземпляра."
  remarks: ''
  example:
  - "The following example outputs information to the console for each speech recognition grammar that is currently loaded by a speech recognizer.  \n  \n> [!IMPORTANT]\n>  Copy the grammar collection to avoid errors if the collection is modified while this method enumerates the elements of the collection.  \n  \n```c#  \n  \nprivate static void ListGrammars(SpeechRecognitionEngine recognizer)  \n{  \n  string qualifier;  \n  List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n  foreach (Grammar g in grammars)  \n  {  \n    qualifier = (g.Enabled) ? \"enabled\" : \"disabled\";  \n  \n    Console.WriteLine(\"Grammar {0} is loaded and is {1}.\",  \n      g.Name, qualifier);  \n  }  \n}  \n```"
  syntax:
    content: public System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.Grammar> Grammars { get; }
    return:
      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.Grammar}
      description: "Коллекция <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> объектов."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Grammars*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
  id: InitialSilenceTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: InitialSilenceTimeout
  nameWithType: SpeechRecognitionEngine.InitialSilenceTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возвращает или задает промежуток времени, в течение которого <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> принимает входной содержащего только бездействия перед окончательным утверждением распознавания."
  remarks: "Каждый распознаватель речи использует алгоритм для различения бездействия и речи. Если вход распознаватель бездействия во время начального времени ожидания бездействия, распознаватель завершает операции распознавания.      -Для распознавания асинхронных операций и эмуляции, вызывает распознаватель <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>событий, где <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=fullName>свойство `true`и <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName>свойство `null`.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>      — Для распознавания синхронной операции и эмуляции, возвращает распознаватель `null`, вместо допустимым <xref:System.Speech.Recognition.RecognitionResult>.</xref:System.Speech.Recognition.RecognitionResult>       Если интервал времени ожидания бездействия начальной имеет значение 0, распознаватель не выполняет проверку времени ожидания бездействия начальной. Интервал времени ожидания может быть любым положительным значением. Значение по умолчанию — 0 секунд."
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example sets the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> and InitialSilenceTimeout properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> before initiating speech recognition. Handlers for the speech recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> events output event information to the console to demonstrate how the InitialSilenceTimeout properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> properties affect recognition operations.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        // Load a Grammar object.  \n        recognizer.LoadGrammar(CreateServicesGrammar(\"FindServices\"));  \n  \n        // Add event handlers.  \n        recognizer.AudioStateChanged +=  \n          new EventHandler<AudioStateChangedEventArgs>(  \n            AudioStateChangedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(3);  \n        recognizer.BabbleTimeout = TimeSpan.FromSeconds(2);  \n        recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1);  \n        recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.5);  \n  \n        Console.WriteLine(\"BabbleTimeout: {0}\", recognizer.BabbleTimeout);  \n        Console.WriteLine(\"InitialSilenceTimeout: {0}\", recognizer.InitialSilenceTimeout);  \n        Console.WriteLine(\"EndSilenceTimeout: {0}\", recognizer.EndSilenceTimeout);  \n        Console.WriteLine(\"EndSilenceTimeoutAmbiguous: {0}\", recognizer.EndSilenceTimeoutAmbiguous);  \n        Console.WriteLine();  \n  \n        // Start asynchronous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Single);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Create a grammar and build it into a Grammar object.   \n    static Grammar CreateServicesGrammar(string grammarName)  \n    {  \n  \n      // Create a grammar for finding services in different cities.  \n      Choices services = new Choices(new string[] { \"restaurants\", \"hotels\", \"gas stations\" });  \n      Choices cities = new Choices(new string[] { \"Seattle\", \"Boston\", \"Dallas\" });  \n  \n      GrammarBuilder findServices = new GrammarBuilder(\"Find\");  \n      findServices.Append(services);  \n      findServices.Append(\"near\");  \n      findServices.Append(cities);  \n  \n      // Create a Grammar object from the GrammarBuilder..  \n      Grammar servicesGrammar = new Grammar(findServices);  \n      servicesGrammar.Name = (\"FindServices\");  \n      return servicesGrammar;  \n    }  \n  \n    // Handle the AudioStateChanged event.  \n    static void AudioStateChangedHandler(  \n      object sender, AudioStateChangedEventArgs e)  \n    {  \n      Console.WriteLine(\"AudioStateChanged ({0}): {1}\",  \n        DateTime.Now.ToString(\"mm:ss.f\"), e.AudioState);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"RecognizeCompleted ({0}):\",  \n        DateTime.Now.ToString(\"mm:ss.f\"));  \n  \n      string resultText;  \n      if (e.Result != null) { resultText = e.Result.Text; }  \n      else { resultText = \"<null>\"; }  \n  \n      Console.WriteLine(  \n        \" BabbleTimeout: {0}; InitialSilenceTimeout: {1}; Result text: {2}\",  \n        e.BabbleTimeout, e.InitialSilenceTimeout, resultText);  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\" Exception message: \", e.Error.Message);  \n      }  \n  \n      // Start the next asynchronous recognition operation.  \n      ((SpeechRecognitionEngine)sender).RecognizeAsync(RecognizeMode.Single);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public TimeSpan InitialSilenceTimeout { get; set; }
    return:
      type: System.TimeSpan
      description: "Длительность периода бездействия."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "Это свойство имеет значение меньше 0 секунд."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers
  id: InstalledRecognizers
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: InstalledRecognizers()
  nameWithType: SpeechRecognitionEngine.InstalledRecognizers()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возвращает сведения обо всех распознавателя речи, установленного в текущей системе."
  remarks: "Чтобы получить сведения о текущем распознавателя, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A>свойство.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example uses the collection returned by the InstalledRecognizers method to find a speech recognizer that supports the English language.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Select a speech recognizer that supports English.  \n      RecognizerInfo info = null;  \n      foreach (RecognizerInfo ri in SpeechRecognitionEngine.InstalledRecognizers())  \n      {  \n        if (ri.Culture.TwoLetterISOLanguageName.Equals(\"en\"))  \n        {  \n          info = ri;  \n          break;  \n        }  \n      }  \n      if (info == null) return;  \n  \n      // Create the selected recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(info))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public static System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizerInfo> InstalledRecognizers ();
    parameters: []
    return:
      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizerInfo}
      description: "Только для чтения коллекцию <xref href=&quot;System.Speech.Recognition.RecognizerInfo&quot;> </xref> объекты, которые описывают установленных распознавателей."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)
  id: LoadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: LoadGrammar(Grammar)
  nameWithType: SpeechRecognitionEngine.LoadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Синхронно загружает <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> объекта."
  remarks: "Распознаватель вызывает исключение, если <xref:System.Speech.Recognition.Grammar>объекта уже загружен, загружается асинхронно или не удалось загрузить в любой распознаватель.</xref:System.Speech.Recognition.Grammar> Не удается загрузить один и тот же <xref:System.Speech.Recognition.Grammar>объект в нескольких экземплярах <xref:System.Speech.Recognition.SpeechRecognitionEngine>.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar> Вместо этого создайте новый <xref:System.Speech.Recognition.Grammar>объекта для каждого <xref:System.Speech.Recognition.SpeechRecognitionEngine>экземпляр.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar>       Если выполняется распознаватель, приложения должны использовать <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>Приостановка механизма распознавания речи перед загрузка, выгрузка, включение или отключение грамматика.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>       При загрузке Грамматика, оно включено по умолчанию. Чтобы отключить Грамматика загружена, используйте <xref:System.Speech.Recognition.Grammar.Enabled%2A>свойство.</xref:System.Speech.Recognition.Grammar.Enabled%2A>       Чтобы загрузить <xref:System.Speech.Recognition.Grammar>асинхронно, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.Grammar>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar> and loads it into a speech recognizer.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (  \n      SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void LoadGrammar (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "Объект грамматики для загрузки."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>Grammar</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "<code>Grammar</code>не находится в недопустимом состоянии."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  id: LoadGrammarAsync(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: LoadGrammarAsync(Grammar)
  nameWithType: SpeechRecognitionEngine.LoadGrammarAsync(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Асинхронно загружает Грамматика распознавания речи."
  remarks: "После завершения загрузки в распознаватель <xref:System.Speech.Recognition.Grammar>объекта, он выдает <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted>событий.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted> </xref:System.Speech.Recognition.Grammar> Распознаватель вызывает исключение, если <xref:System.Speech.Recognition.Grammar>объекта уже загружен, загружается асинхронно или не удалось загрузить в любой распознаватель.</xref:System.Speech.Recognition.Grammar> Не удается загрузить один и тот же <xref:System.Speech.Recognition.Grammar>объект в нескольких экземплярах <xref:System.Speech.Recognition.SpeechRecognitionEngine>.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar> Вместо этого создайте новый <xref:System.Speech.Recognition.Grammar>объекта для каждого <xref:System.Speech.Recognition.SpeechRecognitionEngine>экземпляр.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar>       Если выполняется распознаватель, приложения должны использовать <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>Приостановка механизма распознавания речи перед загрузка, выгрузка, включение или отключение грамматика.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>       При загрузке Грамматика, оно включено по умолчанию. Чтобы отключить Грамматика загружена, используйте <xref:System.Speech.Recognition.Grammar.Enabled%2A>свойство.</xref:System.Speech.Recognition.Grammar.Enabled%2A>       Чтобы загрузить грамматику распознавания речи синхронно, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>"
  syntax:
    content: public void LoadGrammarAsync (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "Грамматика распознавания речи для загрузки."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>Grammar</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "<code>Grammar</code>не находится в недопустимом состоянии."
  - type: System.OperationCanceledException
    commentId: T:System.OperationCanceledException
    description: "Асинхронная операция была отменена."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
  id: LoadGrammarCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: LoadGrammarCompleted
  nameWithType: SpeechRecognitionEngine.LoadGrammarCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возникает, когда <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> завершения асинхронной загрузки <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> объекта."
  remarks: "Распознаватель <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>метода запускает асинхронную операцию.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> <xref:System.Speech.Recognition.SpeechRecognitionEngine>Вызывает это событие, если в результате этой операции.</xref:System.Speech.Recognition.SpeechRecognitionEngine> Для получения <xref:System.Speech.Recognition.Grammar>объекта, который загружен распознаватель, используйте <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A>свойство связанного <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>.</xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs> </xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A> </xref:System.Speech.Recognition.Grammar> Для получения текущего <xref:System.Speech.Recognition.Grammar>объектов распознаватель были загружены, использовать распознаватель <xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A>свойство.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A> </xref:System.Speech.Recognition.Grammar>       Если выполняется распознаватель, приложения должны использовать <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>Приостановка механизма распознавания речи перед загрузка, выгрузка, включение или отключение грамматика.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>       При создании делегата LoadGrammarCompleted, необходимо указать метод, обрабатывающий событие. Чтобы связать событие с обработчиком событий, добавьте в событие экземпляр делегата. Обработчик событий вызывается всякий раз, когда происходит событие, пока не будет удален делегат. Дополнительные сведения о делегатах-обработчиках событий см. в разделе [события и делегаты](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example creates an in-process speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation. The example constructs a <xref:System.Speech.Recognition.Grammar> object from each of the completed speech recognition grammars, then asynchronously loads the <xref:System.Speech.Recognition.Grammar> objects to the <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance. Handlers for the recognizer's LoadGrammarCompleted and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> events write to the console the name of the <xref:System.Speech.Recognition.Grammar> object that was used to perform the recognition and the text of the recognition result, respectively.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognitionEngine recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognition engine and set its input.  \n      recognizer = new SpeechRecognitionEngine();  \n      recognizer.SetInputToDefaultAudioDevice();  \n  \n      // Add a handler for the LoadGrammarCompleted event.  \n      recognizer.LoadGrammarCompleted +=  \n        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n      // Add a handler for the SpeechRecognized event.  \n      recognizer.SpeechRecognized +=  \n        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n      // Create the \"yesno\" grammar.  \n      Choices yesChoices = new Choices(new string[] { \"yes\", \"yup\", \"yeah\" });  \n      SemanticResultValue yesValue =  \n          new SemanticResultValue(yesChoices, (bool)true);  \n      Choices noChoices = new Choices(new string[] { \"no\", \"nope\", \"neah\" });  \n      SemanticResultValue noValue =  \n          new SemanticResultValue(noChoices, (bool)false);  \n      SemanticResultKey yesNoKey =  \n          new SemanticResultKey(\"yesno\", new Choices(new GrammarBuilder[] { yesValue, noValue }));  \n      Grammar yesnoGrammar = new Grammar(yesNoKey);  \n      yesnoGrammar.Name = \"yesNo\";  \n  \n      // Create the \"done\" grammar.  \n      Grammar doneGrammar =  \n        new Grammar(new Choices(new string[] { \"done\", \"exit\", \"quit\", \"stop\" }));  \n      doneGrammar.Name = \"Done\";  \n  \n      // Create a dictation grammar.  \n      Grammar dictation = new DictationGrammar();  \n      dictation.Name = \"Dictation\";  \n  \n      // Load grammars to the recognizer.  \n      recognizer.LoadGrammarAsync(yesnoGrammar);  \n      recognizer.LoadGrammarAsync(doneGrammar);  \n      recognizer.LoadGrammarAsync(dictation);  \n  \n      // Start asynchronous, continuous recognition.  \n      recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n      // Keep the console window open.  \n      Console.ReadLine();  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.   \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      string grammarName = e.Grammar.Name;  \n      bool grammarLoaded = e.Grammar.Loaded;  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"LoadGrammar for {0} failed with a {1}.\",  \n        grammarName, e.Error.GetType().Name);  \n  \n        // Add exception handling code here.  \n      }  \n  \n      Console.WriteLine(\"Grammar {0} {1} loaded.\",  \n      grammarName, (grammarLoaded) ? \"is\" : \"is not\");  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar({0}): {1}\", e.Result.Grammar.Name, e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs> LoadGrammarCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.LoadGrammarCompletedEventArgs}
      description: "Для добавления."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
  id: MaxAlternates
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: MaxAlternates
  nameWithType: SpeechRecognitionEngine.MaxAlternates
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возвращает или задает максимальное количество результатов распознавания альтернативный, <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> возвращает для каждой операции распознавания."
  remarks: "<xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>Свойство <xref:System.Speech.Recognition.RecognitionResult>класс содержит коллекцию <xref:System.Speech.Recognition.RecognizedPhrase>объекты, которые представляют возможные интерпретации входных данных.</xref:System.Speech.Recognition.RecognizedPhrase> </xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>       Значение по умолчанию для MaxAlternates равно 10."
  syntax:
    content: public int MaxAlternates { get; set; }
    return:
      type: System.Int32
      description: "Число альтернативных возвращаемых результатов."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "MaxAlternates задано значение меньше 0."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)
  id: QueryRecognizerSetting(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: QueryRecognizerSetting(String)
  nameWithType: SpeechRecognitionEngine.QueryRecognizerSetting(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возвращает значения параметров для распознавателя."
  remarks: "Распознаватель параметров может содержать строку, 64-разрядное целое число или данных адресов памяти. В следующей таблице описаны параметры, которые определены для API речи (SAPI)-совместимые распознавателя. Следующие параметры должны иметь такой же диапазон для каждого распознаватель, который поддерживает параметр. Совместимые SAPI распознаватель не требуется для поддержки этих параметров и может поддерживать другие параметры.      | Имя | Описание |   |----------|-----------------|   | `ResourceUsage`| Указывает распознаватель потребление ресурсов ЦП. Диапазон — от 0 до 100. Значение по умолчанию — 50. |   | `ResponseSpeed`| Указывает длину бездействия в конце однозначным входных данных до завершения операции распознавания, распознаватель речи. Диапазон — от 0 до 10 000 миллисекунд (мс). Этот параметр соответствует распознавателя <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>свойство.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>  По умолчанию = 150ms. |   | `ComplexResponseSpeed`| Указывает длину бездействия в конце неоднозначных входных данных до завершения операции распознавания, распознаватель речи. Диапазон включает от 0 до 10 000 мс. Этот параметр соответствует распознавателя <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>свойство.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> По умолчанию 500 мс. |   | `AdaptationOn`| Указывает, является ли адаптации акустическими модели ON (значение = `1`) или OFF (значение = `0`). Значение по умолчанию — `1` (ON). |   | `PersistedBackgroundAdaptation`| Указывает, является ли фон адаптации ON (значение = `1`) или OFF (значение = `0`), и сохраняет параметр в реестре. Значение по умолчанию — `1` (ON). |       Чтобы обновить параметр средства распознавания, используйте один из <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>методы.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>"
  example:
  - "The following example is part of a console application that outputs the values for a number of the settings defined for the recognizer that supports the en-US locale. The example generates the following output.  \n  \n```  \nSettings for recognizer MS-1033-80-DESK:  \n  \n  ResourceUsage                  is not supported by this recognizer.  \n  ResponseSpeed                  = 150  \n  ComplexResponseSpeed           = 500  \n  AdaptationOn                   = 1  \n  PersistedBackgroundAdaptation  = 1  \n  \nPress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace RecognizerSettings  \n{  \n  class Program  \n  {  \n    static readonly string[] settings = new string[] {  \n      \"ResourceUsage\",  \n      \"ResponseSpeed\",  \n      \"ComplexResponseSpeed\",  \n      \"AdaptationOn\",  \n      \"PersistedBackgroundAdaptation\"  \n    };  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        Console.WriteLine(\"Settings for recognizer {0}:\",  \n          recognizer.RecognizerInfo.Name);  \n        Console.WriteLine();  \n  \n        foreach (string setting in settings)  \n        {  \n          try  \n          {  \n            object value = recognizer.QueryRecognizerSetting(setting);  \n            Console.WriteLine(\"  {0,-30} = {1}\", setting, value);  \n          }  \n          catch  \n          {  \n            Console.WriteLine(\"  {0,-30} is not supported by this recognizer.\",  \n              setting);  \n          }  \n        }  \n      }  \n      Console.WriteLine();  \n  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public object QueryRecognizerSetting (string settingName);
    parameters:
    - id: settingName
      type: System.String
      description: "Имя возвращаемого параметра."
    return:
      type: System.Object
      description: "Значение параметра."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>settingName</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>settingName</code>является пустой строкой (»»)."
  - type: System.Collections.Generic.KeyNotFoundException
    commentId: T:System.Collections.Generic.KeyNotFoundException
    description: "Распознаватель не имеет параметр с таким именем."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize
  id: Recognize
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Recognize()
  nameWithType: SpeechRecognitionEngine.Recognize()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Recognize()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Выполняет операцию распознавания речи синхронной."
  remarks: "Этот метод выполняет операции одного распознавания. Распознаватель выполняет эту операцию для грамматики распознавания речи загружены и включены.       Во время вызова этого метода, распознаватель может инициировать следующие события:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>  Вызывается, когда распознаватель обнаруживает входные данные, его можно определить в качестве речи.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  Возникает, когда входные данные создает неоднозначного соответствия с одним из активных грамматик.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> Вызывается, когда распознаватель завершает операцию распознавания.       Распознаватель не вызывает <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>событий при использовании этого метода.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>       Возвращает метод распознать <xref:System.Speech.Recognition.RecognitionResult>объекта, или `null` , если операция завершится неуспешно.</xref:System.Speech.Recognition.RecognitionResult>       Операции синхронной распознавания может завершиться ошибкой по следующим причинам:-перед интервалы ожидания истекает срок действия не обнаруживается речь <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>или <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>Свойства.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>      -Модуль распознавания обнаруживает речи, но не находит совпадений в одном из его загружены и включены <xref:System.Speech.Recognition.Grammar>объектов.</xref:System.Speech.Recognition.Grammar>       Для выполнения асинхронных распознавания, используйте один из <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>методы.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs one recognition operation.  \n  \n```  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SynchronousRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Modify the initial silence time-out value.  \n        recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5);  \n  \n        // Start synchronous speech recognition.  \n        RecognitionResult result = recognizer.Recognize();  \n  \n        if (result != null)  \n        {  \n          Console.WriteLine(\"Recognized text = {0}\", result.Text);  \n        }  \n        else  \n        {  \n          Console.WriteLine(\"No recognition result available.\");  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to continue...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult Recognize ();
    parameters: []
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "Результат распознавания для входных данных, или <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> , если операция не завершена или распознаватель не включен."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Recognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)
  id: Recognize(System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Recognize(TimeSpan)
  nameWithType: SpeechRecognitionEngine.Recognize(TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Recognize(TimeSpan)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Выполняет операцию распознавания речи синхронный с указанного начального времени ожидания бездействия."
  remarks: "Если модуль распознавания речи обнаруживает речи в течение интервала времени, указанного параметром `initialSilenceTimeout` выполняет операцию распознавания один аргумент распознать и затем прекращает работу.  `initialSilenceTimeout` Параметра заменяет распознавателя <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>свойство.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>       Во время вызова этого метода, распознаватель может инициировать следующие события:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>  Вызывается, когда распознаватель обнаруживает входные данные, его можно определить в качестве речи.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  Возникает, когда входные данные создает неоднозначного соответствия с одним из активных грамматик.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> Вызывается, когда распознаватель завершает операцию распознавания.       Распознаватель не вызывает <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>событий при использовании этого метода.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>       <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize>Возвращает метод <xref:System.Speech.Recognition.RecognitionResult>объекта, или `null` , если операция завершится неуспешно.</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize>       Операции синхронной распознавания может завершиться ошибкой по следующим причинам:-перед интервалы ожидания истекает срок действия не обнаруживается речь <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>или `initialSilenceTimeout` параметр.</xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>      -Модуль распознавания обнаруживает речи, но не находит совпадений в одном из его загружены и включены <xref:System.Speech.Recognition.Grammar>объектов.</xref:System.Speech.Recognition.Grammar>       Для выполнения асинхронных распознавания, используйте один из <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>методы.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs one recognition operation.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SynchronousRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start synchronous speech recognition.  \n        RecognitionResult result = recognizer.Recognize(TimeSpan.FromSeconds(5));  \n  \n        if (result != null)  \n        {  \n          Console.WriteLine(\"Recognized text = {0}\", result.Text);  \n        }  \n        else  \n        {  \n          Console.WriteLine(\"No recognition result available.\");  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to continue...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult Recognize (TimeSpan initialSilenceTimeout);
    parameters:
    - id: initialSilenceTimeout
      type: System.TimeSpan
      description: "Интервал времени, которые распознаватель речи принимает ввода, содержащий только бездействия перед окончательным утверждением распознавания."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "Результат распознавания для входных данных, или <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> , если операция не завершена или распознаватель не включен."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Recognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync
  id: RecognizeAsync
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeAsync()
  nameWithType: SpeechRecognitionEngine.RecognizeAsync()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Выполняет операцию распознавания речи один, асинхронный."
  remarks: "Этот метод выполняет операцию распознавания одного, асинхронный. Распознаватель выполняет операции с грамматики распознавания речи загружены и включены.       Во время вызова этого метода, распознаватель может инициировать следующие события:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>  Вызывается, когда распознаватель обнаруживает входные данные, его можно определить в качестве речи.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  Возникает, когда входные данные создает неоднозначного соответствия с одним из активных грамматик.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> Вызывается, когда распознаватель завершает операцию распознавания.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> Возникает, когда <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>по завершении операции.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>       Чтобы получить результат распознавания асинхронной операции, необходимо присоединить обработчик событий в распознаватель <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>событий.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> Распознаватель вызывает это событие каждый раз, когда его успешного завершения операции распознавания синхронным или асинхронным. Если распознавания не выполнена, <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A>свойство <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>объекта, к которому можно получить в обработчике <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>событие, будет `null`.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A>       Для выполнения синхронного распознавания, используйте один из <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>методы.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic asynchronous speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs one asynchronous recognition operation. Event handlers are included to demonstrate the events that the recognizer raises during the operation.  \n  \n```c#  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace AsynchronousRecognition  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Create a grammar for choosing cities for a flight.  \n        Choices cities = new Choices(new string[]   \n        { \"Los Angeles\", \"New York\", \"Chicago\", \"San Francisco\", \"Miami\", \"Dallas\" });  \n  \n        GrammarBuilder gb = new GrammarBuilder();  \n        gb.Append(\"I want to fly from\");  \n        gb.Append(cities);  \n        gb.Append(\"to\");  \n        gb.Append(cities);  \n  \n        // Construct a Grammar object and load it to the recognizer.  \n        Grammar cityChooser = new Grammar(gb);  \n        cityChooser.Name = (\"City Chooser\");  \n        recognizer.LoadGrammarAsync(cityChooser);  \n  \n        // Attach event handlers.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Assign input to the recognizer and start an asynchronous  \n        // recognition operation.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        completed = false;  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n        recognizer.RecognizeAsync();  \n  \n        // Wait for the operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechDetectedHandler:\");  \n      Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechHypothesizedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognitionRejectedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognizedHandler.\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" In RecognizeCompletedHandler.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \" - Error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \" - BabbleTimeout = {0}; InitialSilenceTimeout = {1}\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \" - AudioPosition = {0}; InputStreamEnded = {1}\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(  \n          \" - Grammar = {0}; Text = {1}; Confidence = {2}\",  \n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  \n        Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\" - No result.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void RecognizeAsync ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)
  id: RecognizeAsync(System.Speech.Recognition.RecognizeMode)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeAsync(RecognizeMode)
  nameWithType: SpeechRecognitionEngine.RecognizeAsync(RecognizeMode)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(RecognizeMode)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Выполняет одну или несколько операций распознавания речи асинхронной."
  remarks: "Если `mode` — <xref:System.Speech.Recognition.RecognizeMode>, распознаватель продолжает выполнение операций асинхронного распознавания до <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A>или <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A>вызывается метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A> </xref:System.Speech.Recognition.RecognizeMode>       Во время вызова этого метода, распознаватель может инициировать следующие события:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>  Вызывается, когда распознаватель обнаруживает входные данные, его можно определить в качестве речи.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  Возникает, когда входные данные создает неоднозначного соответствия с одним из активных грамматик.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> Вызывается, когда распознаватель завершает операцию распознавания.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> Возникает, когда <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>по завершении операции.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>       Чтобы получить результат распознавания асинхронной операции, необходимо присоединить обработчик событий в распознаватель <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>событий.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> Распознаватель вызывает это событие каждый раз, когда его успешного завершения операции распознавания синхронным или асинхронным. Если распознавания не выполнена, <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A>свойство <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>объекта, к которому можно получить в обработчике <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>событие, будет `null`.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A>       Распознавание асинхронной операции могут завершаться неудачей по следующим причинам:-перед интервалы ожидания истекает срок действия не обнаруживается речь <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>или <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>Свойства.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>      -Модуль распознавания обнаруживает речи, но не находит совпадений в одном из его загружены и включены <xref:System.Speech.Recognition.Grammar>объектов.</xref:System.Speech.Recognition.Grammar>       Для выполнения синхронного распознавания, используйте один из <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>методы.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic asynchronous speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs multiple asynchronous recognition operations. The asynchronous operations are cancelled after 30 seconds. Event handlers are included to demonstrate the events that the recognizer raises during the operation.  \n  \n```c#  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace AsynchronousRecognition  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Create a grammar for choosing cities for a flight.  \n        Choices cities = new Choices(new string[] { \"Los Angeles\", \"New York\", \"Chicago\", \"San Francisco\", \"Miami\", \"Dallas\" });  \n  \n        GrammarBuilder gb = new GrammarBuilder();  \n        gb.Append(\"I want to fly from\");  \n        gb.Append(cities);  \n        gb.Append(\"to\");  \n        gb.Append(cities);  \n  \n        // Construct a Grammar object and load it to the recognizer.  \n        Grammar cityChooser = new Grammar(gb);  \n        cityChooser.Name = (\"City Chooser\");  \n        recognizer.LoadGrammarAsync(cityChooser);  \n  \n        // Attach event handlers.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Assign input to the recognizer and start asynchronous  \n        // recognition.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        completed = false;  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Wait 30 seconds, and then cancel asynchronous recognition.  \n        Thread.Sleep(TimeSpan.FromSeconds(30));  \n        recognizer.RecognizeAsyncCancel();  \n  \n        // Wait for the operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechDetectedHandler:\");  \n      Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechHypothesizedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognitionRejectedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognizedHandler.\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" In RecognizeCompletedHandler.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \" - Error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \" - BabbleTimeout = {0}; InitialSilenceTimeout = {1}\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \" - AudioPosition = {0}; InputStreamEnded = {1}\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(  \n          \" - Grammar = {0}; Text = {1}; Confidence = {2}\",  \n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  \n        Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\" - No result.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void RecognizeAsync (System.Speech.Recognition.RecognizeMode mode);
    parameters:
    - id: mode
      type: System.Speech.Recognition.RecognizeMode
      description: "Указывает, следует ли выполнять одну или несколько операций распознавания."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel
  id: RecognizeAsyncCancel
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeAsyncCancel()
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncCancel()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Завершает асинхронную распознавания без ожидания завершения текущей операции распознавания."
  remarks: "Этот метод немедленно завершает асинхронную распознавания. Если текущая операция асинхронной распознавания получает входные данные, входные данные усечены, и завершения операции с существующие данные. Вызывает распознаватель <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>или <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>событие, когда асинхронная операция отменяется и задает <xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A>Свойства <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>для `true`.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> Этот метод отменяет асинхронные операции, инициированные <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>и <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>методы.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>       Для остановки асинхронной распознавания без усечения входных данных, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A>"
  example:
  - "The following example shows part of a console application that demonstrates the use of the RecognizeAsyncCancel method. The example creates and loads a speech recognition grammar, initiates a continuing asynchronous recognition operation, and then pauses 2 seconds before it cancels the operation. The recognizer receives input from the file, c:\\temp\\audioinput\\sample.wav. Event handlers are included to demonstrate the events that the recognizer raises during the operation.  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace AsynchronousRecognition  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Create and load a dictation grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Attach event handlers.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Begin asynchronous recognition from pre-recorded input.  \n        recognizer.SetInputToWaveFile(@\"c:\\temp\\audioinput\\sample.wav\");  \n  \n        completed = false;  \n        Console.WriteLine(\"Begin continuing asynchronous recognition...\");  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Wait 2 seconds and then cancel the recognition operation.  \n        Thread.Sleep(TimeSpan.FromSeconds(2));  \n        recognizer.RecognizeAsyncCancel();  \n  \n        // Wait for the operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechDetectedHandler:\");  \n      Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechHypothesizedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognitionRejectedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognizedHandler.\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" In RecognizeCompletedHandler.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \" - Error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n      if (e.Cancelled)  \n      {  \n        Console.WriteLine(\" - asynchronous operation canceled.\");  \n      }  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \" - BabbleTimeout = {0}; InitialSilenceTimeout = {1}\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \" - AudioPosition = {0}; InputStreamEnded = {1}\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(  \n          \" - Grammar = {0}; Text = {1}; Confidence = {2}\",  \n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\" - No result.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public void RecognizeAsyncCancel ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop
  id: RecognizeAsyncStop
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeAsyncStop()
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncStop()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Остановка асинхронных распознавания после завершения текущей операции распознавания."
  remarks: "Этот метод завершает асинхронную распознавания без усечения входных данных. Если текущая операция асинхронной распознавания получает входные данные, распознаватель продолжает принимать входные данные до завершения текущей операции распознавания. Вызывает распознаватель <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>или <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>событие, когда асинхронная операция прекращается и задает <xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A>Свойства <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>для `true`.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> Этот метод останавливает асинхронных операций, инициированные <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>и <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>методы.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>       Чтобы немедленно отменить асинхронную распознавания с только существующие данные, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A>"
  example:
  - "The following example shows part of a console application that demonstrates the use of the RecognizeAsyncStop method. The example creates and loads a speech recognition grammar, initiates a continuing asynchronous recognition operation, and then pauses 2 seconds before it stops the operation. The recognizer receives input from the file, c:\\temp\\audioinput\\sample.wav. Event handlers are included to demonstrate the events that the recognizer raises during the operation.  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace AsynchronousRecognition  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Create and load a dictation grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Attach event handlers.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Begin asynchronous recognition from pre-recorded input.  \n        recognizer.SetInputToWaveFile(@\"c:\\temp\\audioinput\\sample.wav\");  \n  \n        completed = false;  \n        Console.WriteLine(\"Begin continuing asynchronous recognition...\");  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Wait 2 seconds and then stop the recognition operation.  \n        Thread.Sleep(TimeSpan.FromSeconds(2));  \n        recognizer.RecognizeAsyncStop();  \n  \n        // Wait for the operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechDetectedHandler:\");  \n      Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechHypothesizedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognitionRejectedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognizedHandler.\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" In RecognizeCompletedHandler.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \" - Error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n      if (e.Cancelled)  \n      {  \n        Console.WriteLine(\" - asynchronous operation canceled.\");  \n      }  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \" - BabbleTimeout = {0}; InitialSilenceTimeout = {1}\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \" - AudioPosition = {0}; InputStreamEnded = {1}\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(  \n          \" - Grammar = {0}; Text = {1}; Confidence = {2}\",  \n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\" - No result.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void RecognizeAsyncStop ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
  id: RecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeCompleted
  nameWithType: SpeechRecognitionEngine.RecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возникает, когда <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> завершает операцию асинхронного распознавания."
  remarks: "<xref:System.Speech.Recognition.SpeechRecognitionEngine>Объекта <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>метод инициирует операцию асинхронной распознавания.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine> Если распознаватель завершает асинхронную операцию, это событие вызывается.       Использовать обработчик для события RecognizeCompleted, можно открыть <xref:System.Speech.Recognition.RecognitionResult>в <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>объекта.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.Speech.Recognition.RecognitionResult> Если распознавания не выполнена, <xref:System.Speech.Recognition.RecognitionResult>будет `null`.</xref:System.Speech.Recognition.RecognitionResult> Чтобы определить, вызвана ли время ожидания или прерывании звукового ввода распознавания сбой, можно получить доступ к свойства <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A>, или <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A>.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A>       В разделе <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>класс для получения дополнительной информации.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs>       Чтобы получить сведения о наиболее подходящих отклоненных распознавания, присоединить обработчик для <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>событий.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>       При создании делегата RecognizeCompleted, необходимо указать метод, обрабатывающий событие. Чтобы связать событие с обработчиком событий, добавьте в событие экземпляр делегата. Обработчик событий вызывается всякий раз, когда происходит событие, пока не будет удален делегат. Дополнительные сведения о делегатах-обработчиках событий см. в разделе [события и делегаты](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\" or \"Display albums gospel\". The example uses a handler for the RecognizeCompleted event to display information about the results of recognition in the console.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine())  \n      {  \n  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display\");  \n        mediaMenu.Append(\"the list of\", 0, 1);  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\", 0, 1);  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category.\", 0, 1);  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  \n        recognizer.LoadGrammarCompleted +=   \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  \n    {  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \"RecognizeCompleted, error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \"RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \"RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"RecognizeCompleted:\");  \n        Console.WriteLine(\"  Grammar: \" + e.Result.Grammar.Name);  \n        Console.WriteLine(\"  Recognized text: \" + e.Result.Text);  \n        Console.WriteLine(\"  Confidence score: \" + e.Result.Confidence);  \n        Console.WriteLine(\"  Audio position: \" + e.AudioPosition);  \n      }  \n  \n      else  \n      {  \n        Console.WriteLine(\"RecognizeCompleted: No result.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded:  \" + e.Grammar.Name);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.RecognizeCompletedEventArgs> RecognizeCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.RecognizeCompletedEventArgs}
      description: "Для добавления."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
  id: RecognizerAudioPosition
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognitionEngine.RecognizerAudioPosition
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Получает текущее расположение <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> в аудио входных данных, его обработки."
  remarks: "Положение аудио для каждого процессора распознавания речи. Когда она включена, устанавливается нулевое значение входного потока.       Ссылки на свойства RecognizerAudioPosition <xref:System.Speech.Recognition.SpeechRecognitionEngine>положение объекта в его аудио входных данных.</xref:System.Speech.Recognition.SpeechRecognitionEngine> В отличие от этого <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>свойство ссылается на позицию устройство ввода в созданный аудиопотока.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> Эти позиции могут быть разными. Например, если распознаватель получила ввода, для которого он не еще создан результатов распознавания, то значение свойства RecognizerAudioPosition меньше, чем значение <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>Свойства.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>"
  syntax:
    content: public TimeSpan RecognizerAudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "Позиция распознаватель в аудио входных данных, его обработки."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
  id: RecognizerInfo
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizerInfo
  nameWithType: SpeechRecognitionEngine.RecognizerInfo
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возвращает сведения о текущем экземпляре <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "Чтобы получить сведения обо всех распознавателя речи, установленного для текущей системы, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>"
  example:
  - "The following example gets a partial list of data for the current in-process speech recognition engine. For more information, see <xref:System.Speech.Recognition.RecognizerInfo>.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace RecognitionEngine  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer = new SpeechRecognitionEngine())  \n      {  \n        Console.WriteLine(\"Information for the current speech recognition engine:\");  \n        Console.WriteLine(\"  Name: {0}\", recognizer.RecognizerInfo.Name);  \n        Console.WriteLine(\"  Culture: {0}\", recognizer.RecognizerInfo.Culture.ToString());  \n        Console.WriteLine(\"  Description: {0}\", recognizer.RecognizerInfo.Description);  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizerInfo RecognizerInfo { get; }
    return:
      type: System.Speech.Recognition.RecognizerInfo
      description: "Сведения о текущем распознавания речи."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
  id: RecognizerUpdateReached
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizerUpdateReached
  nameWithType: SpeechRecognitionEngine.RecognizerUpdateReached
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возникает, когда промежуточных <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> приостанавливает свою работу, чтобы принять изменения."
  remarks: "Приложения должны использовать <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>приостановка выполняющегося экземпляра <xref:System.Speech.Recognition.SpeechRecognitionEngine>перед набором параметров или его <xref:System.Speech.Recognition.Grammar>объектов.</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> <xref:System.Speech.Recognition.SpeechRecognitionEngine>Вызывает это событие, когда она готова к принятию изменений.</xref:System.Speech.Recognition.SpeechRecognitionEngine>       Например, в то время как <xref:System.Speech.Recognition.SpeechRecognitionEngine>является приостановлена, то можно загрузить, выгрузить, включения и отключения <xref:System.Speech.Recognition.Grammar>объектов и изменить значения для <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, и <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>Свойства.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> </xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognitionEngine> Дополнительные сведения см. в разделе <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>       При создании делегата RecognizerUpdateReached, необходимо указать метод, обрабатывающий событие. Чтобы связать событие с обработчиком событий, добавьте в событие экземпляр делегата. Обработчик событий вызывается всякий раз, когда происходит событие, пока не будет удален делегат. Дополнительные сведения о делегатах-обработчиках событий см. в разделе [события и делегаты](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects. The application uses the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> method to request the speech recognition engine to pause so it can receive an update. The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.  \n  \n At each update, a handler for RecognizerUpdateReached event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console. As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Collections.Generic;  \nusing System.Threading;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognitionEngine recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognition engine and configure its input.  \n      using (recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Create the first grammar - Farm.  \n        Choices animals = new Choices(new string[] { \"cow\", \"pig\", \"goat\" });  \n        GrammarBuilder farm = new GrammarBuilder(animals);  \n        Grammar farmAnimals = new Grammar(farm);  \n        farmAnimals.Name = \"Farm\";  \n  \n        // Create the second grammar - Fruit.  \n        Choices fruit = new Choices(new string[] { \"apples\", \"peaches\", \"oranges\" });  \n        GrammarBuilder favorite = new GrammarBuilder(fruit);  \n        Grammar favoriteFruit = new Grammar(favorite);  \n        favoriteFruit.Name = \"Fruit\";  \n  \n        // Attach event handlers.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.RecognizerUpdateReached +=  \n          new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  \n  \n        // Load the Farm grammar.  \n        recognizer.LoadGrammar(farmAnimals);  \n  \n        // Start asynchronous, continuous recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n        Console.WriteLine(\"Starting asynchronous, continuous recognition\");  \n        Console.WriteLine(\"  Farm grammar is loaded and enabled.\");  \n  \n        // Pause to recognize farm animals.  \n        Thread.Sleep(7000);  \n        Console.WriteLine();  \n  \n        // Request an update and load the Fruit grammar.  \n        recognizer.RequestRecognizerUpdate();  \n        recognizer.LoadGrammarAsync(favoriteFruit);  \n        Thread.Sleep(7000);  \n  \n        // Request an update and unload the Farm grammar.  \n        recognizer.RequestRecognizerUpdate();  \n        recognizer.UnloadGrammar(farmAnimals);  \n        Thread.Sleep(7000);  \n      }  \n  \n      // Keep the console window open.  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // At the update, get the names and enabled status of the currently loaded grammars.  \n    public static void recognizer_RecognizerUpdateReached(  \n      object sender, RecognizerUpdateReachedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Update reached:\");  \n      Thread.Sleep(1000);  \n  \n      string qualifier;  \n      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n      foreach (Grammar g in grammars)  \n      {  \n        qualifier = (g.Enabled) ? \"enabled\" : \"disabled\";  \n        Console.WriteLine(\"  {0} grammar is loaded and {1}.\",  \n        g.Name, qualifier);  \n      }  \n    }  \n  \n    // Write the text of the recognized phrase to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"    Speech recognized: \" + e.Result.Text);  \n    }  \n  \n    // Write a message to the console when recognition fails.  \n    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\"    Recognition attempt failed\");  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs> RecognizerUpdateReached;
    return:
      type: System.EventHandler{System.Speech.Recognition.RecognizerUpdateReachedEventArgs}
      description: "Для добавления."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate
  id: RequestRecognizerUpdate
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RequestRecognizerUpdate()
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Запросы, что распознаватель приостанавливается, чтобы обновить его состояние."
  remarks: "Когда распознаватель приводит к возникновению ошибки <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>события, <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>свойство <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>— `null`.</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>       Чтобы предоставить токен пользователя, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>или <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> Чтобы указать положение аудио смещение, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>"
  example:
  - "The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects. The application uses the RequestRecognizerUpdate method to request the speech recognition engine to pause so it can receive an update. The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.  \n  \n At each update, a handler for <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console. As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Collections.Generic;  \nusing System.Threading;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognitionEngine recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognition engine and configure its input.  \n      using (recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Create the first grammar - Farm.  \n        Choices animals = new Choices(new string[] { \"cow\", \"pig\", \"goat\" });  \n        GrammarBuilder farm = new GrammarBuilder(animals);  \n        Grammar farmAnimals = new Grammar(farm);  \n        farmAnimals.Name = \"Farm\";  \n  \n        // Create the second grammar - Fruit.  \n        Choices fruit = new Choices(new string[] { \"apples\", \"peaches\", \"oranges\" });  \n        GrammarBuilder favorite = new GrammarBuilder(fruit);  \n        Grammar favoriteFruit = new Grammar(favorite);  \n        favoriteFruit.Name = \"Fruit\";  \n  \n        // Attach event handlers.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.RecognizerUpdateReached +=  \n          new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  \n  \n        // Load the Farm grammar.  \n        recognizer.LoadGrammar(farmAnimals);  \n  \n        // Start asynchronous, continuous recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n        Console.WriteLine(\"Starting asynchronous, continuous recognition\");  \n        Console.WriteLine(\"  Farm grammar is loaded and enabled.\");  \n  \n        // Pause to recognize farm animals.  \n        Thread.Sleep(7000);  \n        Console.WriteLine();  \n  \n        // Request an update and load the Fruit grammar.  \n        recognizer.RequestRecognizerUpdate();  \n        recognizer.LoadGrammarAsync(favoriteFruit);  \n        Thread.Sleep(7000);  \n  \n        // Request an update and unload the Farm grammar.  \n        recognizer.RequestRecognizerUpdate();  \n        recognizer.UnloadGrammar(farmAnimals);  \n        Thread.Sleep(7000);  \n      }  \n  \n      // Keep the console window open.  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // At the update, get the names and enabled status of the currently loaded grammars.  \n    public static void recognizer_RecognizerUpdateReached(  \n      object sender, RecognizerUpdateReachedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Update reached:\");  \n      Thread.Sleep(1000);  \n  \n      string qualifier;  \n      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n      foreach (Grammar g in grammars)  \n      {  \n        qualifier = (g.Enabled) ? \"enabled\" : \"disabled\";  \n        Console.WriteLine(\"  {0} grammar is loaded and {1}.\",  \n        g.Name, qualifier);  \n      }  \n    }  \n  \n    // Write the text of the recognized phrase to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"    Speech recognized: \" + e.Result.Text);  \n    }  \n  \n    // Write a message to the console when recognition fails.  \n    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\"    Recognition attempt failed\");  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void RequestRecognizerUpdate ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)
  id: RequestRecognizerUpdate(System.Object)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RequestRecognizerUpdate(Object)
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate(Object)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(Object)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Запросы, что распознаватель приостанавливает для обновления состояния и предоставляет токен пользователя для связанного события."
  remarks: "Когда распознаватель приводит к возникновению ошибки <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>события, <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>свойство <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>содержит значение `userToken` параметр.</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>       Чтобы указать положение аудио смещение, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>"
  syntax:
    content: public void RequestRecognizerUpdate (object userToken);
    parameters:
    - id: userToken
      type: System.Object
      description: "Определенные пользователем сведения, содержащий сведения для операции."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  id: RequestRecognizerUpdate(System.Object,System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RequestRecognizerUpdate(Object,TimeSpan)
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate(Object,TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(Object,TimeSpan)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Запросы, что распознаватель приостанавливается, чтобы обновить его состояние, а также смещение и маркер пользователя для связанного события."
  remarks: "Распознаватель не инициирует запрос на обновление распознаватель пока распознаватель <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>равно текущего <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>плюс `audioPositionAheadToRaiseUpdate`.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>       Когда распознаватель приводит к возникновению ошибки <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>события, <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>свойство <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>содержит значение `userToken` параметр.</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>"
  syntax:
    content: public void RequestRecognizerUpdate (object userToken, TimeSpan audioPositionAheadToRaiseUpdate);
    parameters:
    - id: userToken
      type: System.Object
      description: "Определенные пользователем сведения, содержащий сведения для операции."
    - id: audioPositionAheadToRaiseUpdate
      type: System.TimeSpan
      description: "Смещение от текущего <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*>задержки запроса.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*>"
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)
  id: SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  nameWithType: SpeechRecognitionEngine.SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Настраивает <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> объекта для получения входных данных из аудиопотока."
  remarks: "Если распознаватель достигает конца потока входных данных во время операции распознавания, операции распознавания завершает с доступными входными данными. Все последующие распознавания операции можно создают исключение, пока разработчик не обновит входных данных для распознавателя."
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example uses input from an audio file, example.wav, that contains the phrases, \"testing testing one two three\" and \"mister cooper\", separated by a pause. The example generates the following output.  \n  \n```  \n  \nStarting asynchronous recognition...  \n  Recognized text =  Testing testing 123  \n  Recognized text =  Mr. Cooper  \n  End of stream encountered.  \nDone.  \n  \nPress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.IO;  \nusing System.Speech.AudioFormat;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace InputExamples  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Configure the input to the recognizer.  \n        recognizer.SetInputToAudioStream(  \n          File.OpenRead(@\"c:\\temp\\audioinput\\example.wav\"),  \n          new SpeechAudioFormatInfo(  \n            44100, AudioBitsPerSample.Sixteen, AudioChannel.Mono));  \n  \n        // Attach event handlers.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Perform recognition of the whole file.  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n        completed = false;  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null && e.Result.Text != null)  \n      {  \n        Console.WriteLine(\"  Recognized text =  {0}\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  Recognized text not available.\");  \n      }  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"  Error encountered, {0}: {1}\",  \n          e.Error.GetType().Name, e.Error.Message);  \n      }  \n      if (e.Cancelled)  \n      {  \n        Console.WriteLine(\"  Operation cancelled.\");  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(\"  End of stream encountered.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void SetInputToAudioStream (System.IO.Stream audioSource, System.Speech.AudioFormat.SpeechAudioFormatInfo audioFormat);
    parameters:
    - id: audioSource
      type: System.IO.Stream
      description: "Аудио входной поток."
    - id: audioFormat
      type: System.Speech.AudioFormat.SpeechAudioFormatInfo
      description: "Формат звукового ввода."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice
  id: SetInputToDefaultAudioDevice
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToDefaultAudioDevice()
  nameWithType: SpeechRecognitionEngine.SetInputToDefaultAudioDevice()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Настраивает <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> объекта для получения входных данных из звуковое устройство по умолчанию."
  remarks: ''
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example uses output from the default audio device, performs multiple, asynchronous recognition operations, and exits when a user utters the phrase, \"exit\".  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace DefaultInput  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition has finished.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load the exit grammar.  \n        Grammar exitGrammar = new Grammar(new GrammarBuilder(\"exit\"));  \n        exitGrammar.Name = \"Exit Grammar\";  \n        recognizer.LoadGrammar(exitGrammar);  \n  \n        // Create and load the dictation grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Attach event handlers to the recognizer.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Assign input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Begin asynchronous recognition.  \n        Console.WriteLine(\"Starting recognition...\");  \n        completed = false;  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Wait for recognition to finish.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Speech recognized:\");  \n      string grammarName = \"<not available>\";  \n      if (e.Result.Grammar.Name != null &&  \n        !e.Result.Grammar.Name.Equals(string.Empty))  \n      {  \n        grammarName = e.Result.Grammar.Name;  \n      }  \n      Console.WriteLine(\"    {0,-17} - {1}\",  \n        grammarName, e.Result.Text);  \n  \n      if (grammarName.Equals(\"Exit Grammar\"))  \n      {  \n        ((SpeechRecognitionEngine)sender).RecognizeAsyncCancel();  \n      }  \n    }  \n  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Recognition completed.\");  \n      completed = true;  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public void SetInputToDefaultAudioDevice ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull
  id: SetInputToNull
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToNull()
  nameWithType: SpeechRecognitionEngine.SetInputToNull()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Отключает входных данных для распознавания речи."
  remarks: "Настройка <xref:System.Speech.Recognition.SpeechRecognitionEngine>объекта отсутствие ввода при использовании <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>и <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>методов, или при получении механизма распознавания временно в автономном режиме.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine>"
  syntax:
    content: public void SetInputToNull ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)
  id: SetInputToWaveFile(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToWaveFile(String)
  nameWithType: SpeechRecognitionEngine.SetInputToWaveFile(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Настраивает <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> объекта для получения входных данных из файла сигнала звуковой формат (.wav)."
  remarks: "Если распознаватель достигает конца входного файла во время операции распознавания, операции распознавания завершает с доступными входными данными. Все последующие распознавания операции можно создают исключение, пока разработчик не обновит входных данных для распознавателя."
  example:
  - "The following example performs recognition on the audio in a .wav file and writes the recognized text to the console.  \n  \n```  \nusing System;  \nusing System.IO;  \nusing System.Speech.Recognition;  \nusing System.Speech.AudioFormat;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine())  \n      {  \n  \n        // Create and load a grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Configure the input to the recognizer.  \nrecognizer.SetInputToWaveFile(@\"c:\\temp\\SampleWAVInput.wav\");  \n  \n        // Attach event handlers for the results of recognition.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.RecognizeCompleted +=   \n          new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  \n  \n        // Perform recognition on the entire file.  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n        completed = false;  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        while (!completed)  \n        {  \n          Console.ReadLine();  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null && e.Result.Text != null)  \n      {  \n        Console.WriteLine(\"  Recognized text =  {0}\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  Recognized text not available.\");  \n      }  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  \n    {  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"  Error encountered, {0}: {1}\",  \n        e.Error.GetType().Name, e.Error.Message);  \n      }  \n      if (e.Cancelled)  \n      {  \n        Console.WriteLine(\"  Operation cancelled.\");  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(\"  End of stream encountered.\");  \n      }  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void SetInputToWaveFile (string path);
    parameters:
    - id: path
      type: System.String
      description: "Путь к файлу для использования в качестве входных данных."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)
  id: SetInputToWaveStream(System.IO.Stream)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToWaveStream(Stream)
  nameWithType: SpeechRecognitionEngine.SetInputToWaveStream(Stream)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(Stream)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Настраивает <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> объекта для получения входных данных из потока, который содержит данные сигнала звуковой формат (.wav)."
  remarks: "Если распознаватель достигает конца потока входных данных во время операции распознавания, операции распознавания завершает с доступными входными данными. Все последующие распознавания операции можно создают исключение, пока разработчик не обновит входных данных для распознавателя."
  syntax:
    content: public void SetInputToWaveStream (System.IO.Stream audioSource);
    parameters:
    - id: audioSource
      type: System.IO.Stream
      description: "Поток, содержащий звуковых данных."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
  id: SpeechDetected
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechDetected
  nameWithType: SpeechRecognitionEngine.SpeechDetected
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возникает, когда <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> обнаруживает входные данные, его можно определить в качестве речи."
  remarks: "Каждый распознаватель речи использует алгоритм для различения бездействия и речи. Когда <xref:System.Speech.Recognition.SpeechRecognitionEngine>выполняет операцию распознавания речи, он вызывает событие SpeechDetected, когда использует алгоритм идентифицирует входные данные как речи.</xref:System.Speech.Recognition.SpeechRecognitionEngine> <xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A>Свойства связанного <xref:System.Speech.Recognition.SpeechDetectedEventArgs>объект указывает расположение во входном потоке, где распознаватель обнаружены речи.</xref:System.Speech.Recognition.SpeechDetectedEventArgs> </xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A> <xref:System.Speech.Recognition.SpeechRecognitionEngine>Вызывает событие SpeechDetected до его вызывает любой из <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>, или <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>события.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine>       Дополнительные сведения см. <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>, и <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>методы.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>       При создании делегата SpeechDetected, необходимо указать метод, обрабатывающий событие. Чтобы связать событие с обработчиком событий, добавьте в событие экземпляр делегата. Обработчик событий вызывается всякий раз, когда происходит событие, пока не будет удален делегат. Дополнительные сведения о делегатах-обработчиках событий см. в разделе [события и делегаты](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example is part of a console application for choosing origin and destination cities for a flight. The application recognizes phrases such as \"I want to fly from Miami to Chicago.\"  The example uses the SpeechDetected event to report the <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> each time speech is detected.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine())  \n      {  \n  \n        // Create a grammar.  \n        Choices cities = new Choices(new string[] {   \n          \"Los Angeles\", \"New York\", \"Chicago\", \"San Francisco\", \"Miami\", \"Dallas\" });  \n  \n        GrammarBuilder gb = new GrammarBuilder();  \n        gb.Append(\"I would like to fly from\");  \n        gb.Append(cities);  \n        gb.Append(\"to\");  \n        gb.Append(cities);  \n  \n        // Create a Grammar object and load it to the recognizer.  \n        Grammar g = new Grammar(gb);  \n        g.Name = (\"City Chooser\");  \n        recognizer.LoadGrammarAsync(g);  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Speech detected at AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs> SpeechDetected;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechDetectedEventArgs}
      description: "Для добавления."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
  id: SpeechHypothesized
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechHypothesized
  nameWithType: SpeechRecognitionEngine.SpeechHypothesized
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возникает, когда <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> распознала слова или слов, которые могут быть компонентом нескольких фраз в грамматике."
  remarks: "<xref:System.Speech.Recognition.SpeechRecognitionEngine>Создает многочисленные SpeechHypothesized события, как он пытается определить входной фразу.</xref:System.Speech.Recognition.SpeechRecognitionEngine> Можно получить доступ к текст частично распознанной фразы в <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>свойство <xref:System.Speech.Recognition.SpeechHypothesizedEventArgs>объекта в обработчик события SpeechHypothesized.</xref:System.Speech.Recognition.SpeechHypothesizedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> Как правило обработка этих событий полезно только для отладки.       <xref:System.Speech.Recognition.SpeechHypothesizedEventArgs>является производным от <xref:System.Speech.Recognition.RecognitionEventArgs>.</xref:System.Speech.Recognition.RecognitionEventArgs></xref:System.Speech.Recognition.SpeechHypothesizedEventArgs>       Дополнительные сведения см. <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>свойство и <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>, и <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>методы.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>       При создании делегата SpeechHypothesized, необходимо указать метод, обрабатывающий событие. Чтобы связать событие с обработчиком событий, добавьте в событие экземпляр делегата. Обработчик событий вызывается всякий раз, когда происходит событие, пока не будет удален делегат. Дополнительные сведения о делегатах-обработчиках событий см. в разделе [события и делегаты](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\". The example uses the SpeechHypothesized event to display incomplete phrase fragments in the console as they are recognized.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine())  \n      {  \n  \n        // Create a grammar.  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display the list of\");  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\");  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category.\");  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(recognizer_SpeechHypothesized);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void recognizer_SpeechHypothesized(object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech hypothesized: \" + e.Result.Text);  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n      Console.WriteLine();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine();   \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs> SpeechHypothesized;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechHypothesizedEventArgs}
      description: "Для добавления."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
  id: SpeechRecognitionRejected
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionRejected
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionRejected
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возникает, когда <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> получает входные данные, не соответствует ни одному из его загружены и включены <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> объектов."
  remarks: "Распознаватель это событие вызывается, если он определяет, что входные данные не совпадает с достаточно уверенности все его загрузки и включена <xref:System.Speech.Recognition.Grammar>объектов.</xref:System.Speech.Recognition.Grammar> <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>Свойство <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>содержит отклоненных <xref:System.Speech.Recognition.RecognitionResult>объекта.</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> Обработчик события SpeechRecognitionRejected можно использовать для получения распознавания <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>, были отклонены и их <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>оценок.</xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> </xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>       Если приложение использует <xref:System.Speech.Recognition.SpeechRecognitionEngine>экземпляр, можно изменить уровень достоверности какие речь приняты или отклонены с одним из входных данных <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>методы.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine> Вы можете изменить реакцию распознавания речи ввода с помощью отличных от речи <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, и <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>Свойства.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>       При создании делегата SpeechRecognitionRejected, необходимо указать метод, обрабатывающий событие. Чтобы связать событие с обработчиком событий, добавьте в событие экземпляр делегата. Обработчик событий вызывается всякий раз, когда происходит событие, пока не будет удален делегат. Дополнительные сведения о делегатах-обработчиках событий см. в разделе [события и делегаты](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\" or \"Display albums gospel\". The example uses a handler for the SpeechRecognitionRejected event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> to produce a successful recognition. The handler also displays recognition result <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> that were rejected because of low confidence scores.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create a grammar.  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display\");  \n        mediaMenu.Append(\"the list of\", 0, 1);  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\", 0, 1);  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category\", 0, 1);  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech input was rejected.\");  \n      foreach (RecognizedPhrase phrase in e.Result.Alternates)  \n      {  \n      Console.WriteLine(\"  Rejected phrase: \" + phrase.Text);  \n      Console.WriteLine(\"  Confidence score: \" + phrase.Confidence);  \n      }  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n      Console.WriteLine(\"  Confidence score: \" + e.Result.Confidence);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> SpeechRecognitionRejected;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechRecognitionRejectedEventArgs}
      description: "Для добавления."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
  id: SpeechRecognized
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognized
  nameWithType: SpeechRecognitionEngine.SpeechRecognized
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Возникает, когда <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> получает входные данные, который соответствует любому из ее загрузить и включены <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> объектов."
  remarks: "Можно инициировать операцию распознавания, используя один из <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>или <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>методы.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> Распознаватель регистрирует событие SpeechRecognized, если обнаружит, что ввод соответствует одной из его загруженного <xref:System.Speech.Recognition.Grammar>объекты с достаточный уровень достоверности для использования в качестве распознавания.</xref:System.Speech.Recognition.Grammar> <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>Свойство <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>содержит принятое <xref:System.Speech.Recognition.RecognitionResult>объекта.</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> Обработчики событий SpeechRecognized можно получить распознанной фразы, а также список распознавания <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>с нижней достоверности.</xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>       Если приложение использует <xref:System.Speech.Recognition.SpeechRecognitionEngine>экземпляр, можно изменить уровень достоверности какие речь приняты или отклонены с одним из входных данных <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>методы.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine>  Вы можете изменить реакцию распознавания речи ввода с помощью отличных от речи <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, и <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>Свойства.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>       Когда распознаватель получает входные данные, соответствующие грамматики <xref:System.Speech.Recognition.Grammar>объект может вызывать его <xref:System.Speech.Recognition.Grammar.SpeechRecognized>событий.</xref:System.Speech.Recognition.Grammar.SpeechRecognized> </xref:System.Speech.Recognition.Grammar> <xref:System.Speech.Recognition.Grammar>Объекта <xref:System.Speech.Recognition.Grammar.SpeechRecognized>события до события SpeechRecognized распознаватель речи.</xref:System.Speech.Recognition.Grammar.SpeechRecognized> </xref:System.Speech.Recognition.Grammar> Все задачи, относящиеся к определенной грамматики всегда должна выполняться обработчик для <xref:System.Speech.Recognition.Grammar.SpeechRecognized>событий.</xref:System.Speech.Recognition.Grammar.SpeechRecognized>       При создании делегата SpeechRecognized, необходимо указать метод, обрабатывающий событие. Чтобы связать событие с обработчиком событий, добавьте в событие экземпляр делегата. Обработчик событий вызывается всякий раз, когда происходит событие, пока не будет удален делегат. Дополнительные сведения о делегатах-обработчиках событий см. в разделе [события и делегаты](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example is part of a console application that creates speech recognition grammar, constructs a <xref:System.Speech.Recognition.Grammar> object, and loads it into the <xref:System.Speech.Recognition.SpeechRecognitionEngine> to perform recognition. The example demonstrates speech input to a <xref:System.Speech.Recognition.SpeechRecognitionEngine>, the associated recognition results, and the associated events raised by the speech recognizer.  \n  \n Spoken input such as \"I want to fly from Chicago to Miami\" will trigger a SpeechRecognized event. Speaking the phrase \"Fly me from Houston to Chicago \" will not trigger a SpeechRecognized event.  \n  \n The example uses a handler for the SpeechRecognized event to display successfully recognized phrases and the semantics they contain in the console.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer = new SpeechRecognitionEngine())  \n      {  \n  \n        // Create SemanticResultValue objects that contain cities and airport codes.  \n        SemanticResultValue chicago = new SemanticResultValue(\"Chicago\", \"ORD\");  \n        SemanticResultValue boston = new SemanticResultValue(\"Boston\", \"BOS\");  \n        SemanticResultValue miami = new SemanticResultValue(\"Miami\", \"MIA\");  \n        SemanticResultValue dallas = new SemanticResultValue(\"Dallas\", \"DFW\");  \n  \n        // Create a Choices object and add the SemanticResultValue objects, using  \n        // implicit conversion from SemanticResultValue to GrammarBuilder  \n        Choices cities = new Choices();  \n        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  \n  \n        // Build the phrase and add SemanticResultKeys.  \n        GrammarBuilder chooseCities = new GrammarBuilder();  \n        chooseCities.Append(\"I want to fly from\");  \n        chooseCities.Append(new SemanticResultKey(\"origin\", cities));  \n        chooseCities.Append(\"to\");  \n        chooseCities.Append(new SemanticResultKey(\"destination\", cities));  \n  \n        // Build a Grammar object from the GrammarBuilder.  \n        Grammar bookFlight = new Grammar(chooseCities);  \n        bookFlight.Name = \"Book Flight\";  \n  \n        // Add a handler for the LoadGrammarCompleted event.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Add a handler for the SpeechRecognized event.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(bookFlight);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n      Console.WriteLine();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized:  \" + e.Result.Text);  \n      Console.WriteLine();  \n      Console.WriteLine(\"Semantic results:\");  \n      Console.WriteLine(\"  The flight origin is \" + e.Result.Semantics[\"origin\"].Value);  \n      Console.WriteLine(\"  The flight destination is \" + e.Result.Semantics[\"destination\"].Value);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs> SpeechRecognized;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechRecognizedEventArgs}
      description: "Для добавления."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars
  id: UnloadAllGrammars
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: UnloadAllGrammars()
  nameWithType: SpeechRecognitionEngine.UnloadAllGrammars()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Выгружает все <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> объектов из распознавателя."
  remarks: "Если загружается распознаватель <xref:System.Speech.Recognition.Grammar>асинхронно, этот метод ожидает <xref:System.Speech.Recognition.Grammar>загружается, прежде чем он выгружает все <xref:System.Speech.Recognition.Grammar>объекты из <xref:System.Speech.Recognition.SpeechRecognitionEngine>экземпляра.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.Grammar>       Чтобы выгрузить определенной грамматикой, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A>"
  example:
  - "The following example shows part of a console application that demonstrates the synchronous loading and unloading of speech recognition grammars.  \n  \n```  \nLoading grammars...  \nLoaded grammars:  \n - Grammar1  \n - Grammar2  \n - Grammar3  \n  \nUnloading Grammar1...  \nLoaded grammars:  \n - Grammar2  \n - Grammar3  \n  \nUnloading all grammars...  \nNo grammars loaded.  \n  \nPress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Collections.Generic;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace UnloadGrammars  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        Console.WriteLine(\"Loading grammars...\");  \n  \n        // Create and load a number of grammars.  \n        Grammar grammar1 = new Grammar(new GrammarBuilder(\"first grammar\"));  \n        grammar1.Name = \"Grammar1\";  \n        recognizer.LoadGrammar(grammar1);  \n  \n        Grammar grammar2 = new Grammar(new GrammarBuilder(\"second grammar\"));  \n        grammar2.Name = \"Grammar2\";  \n        recognizer.LoadGrammar(grammar2);  \n  \n        Grammar grammar3 = new Grammar(new GrammarBuilder(\"third grammar\"));  \n        grammar3.Name = \"Grammar3\";  \n        recognizer.LoadGrammar(grammar3);  \n  \n        // List the recognizer's loaded grammars.  \n        ListGrammars(recognizer);  \n  \n        // Unload one grammar and list the loaded grammars.  \n        Console.WriteLine(\"Unloading Grammar1...\");  \n        recognizer.UnloadGrammar(grammar1);  \n        ListGrammars(recognizer);  \n  \n        // Unload all grammars and list the loaded grammars.  \n        Console.WriteLine(\"Unloading all grammars...\");  \n        recognizer.UnloadAllGrammars();  \n        ListGrammars(recognizer);  \n      }  \n  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    private static void ListGrammars(SpeechRecognitionEngine recognizer)  \n    {  \n      // Make a copy of the recognizer's grammar collection.  \n      List<Grammar> loadedGrammars = new List<Grammar>(recognizer.Grammars);  \n  \n      if (loadedGrammars.Count > 0)  \n      {  \n        Console.WriteLine(\"Loaded grammars:\");  \n        foreach (Grammar g in recognizer.Grammars)  \n        {  \n          Console.WriteLine(\" - {0}\", g.Name);  \n        }  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No grammars loaded.\");  \n      }  \n      Console.WriteLine();  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public void UnloadAllGrammars ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)
  id: UnloadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: UnloadGrammar(Grammar)
  nameWithType: SpeechRecognitionEngine.UnloadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Выгружает указанный <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> объекта из <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> экземпляра."
  remarks: "Если выполняется распознаватель, приложения должны использовать <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>для приостановки <xref:System.Speech.Recognition.SpeechRecognitionEngine>экземпляра до загрузки, выгрузки, включение или отключение <xref:System.Speech.Recognition.Grammar>объекта.</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> Выгрузка всех <xref:System.Speech.Recognition.Grammar>объектов, используйте <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A>метод.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A> </xref:System.Speech.Recognition.Grammar>"
  example:
  - "The following example shows part of a console application that demonstrates the synchronous loading and unloading of speech recognition grammars.  \n  \n```  \nLoading grammars...  \nLoaded grammars:  \n - Grammar1  \n - Grammar2  \n - Grammar3  \n  \nUnloading Grammar1...  \nLoaded grammars:  \n - Grammar2  \n - Grammar3  \n  \nUnloading all grammars...  \nNo grammars loaded.  \n  \nPress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Collections.Generic;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace UnloadGrammars  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        Console.WriteLine(\"Loading grammars...\");  \n  \n        // Create and load a number of grammars.  \n        Grammar grammar1 = new Grammar(new GrammarBuilder(\"first grammar\"));  \n        grammar1.Name = \"Grammar1\";  \n        recognizer.LoadGrammar(grammar1);  \n  \n        Grammar grammar2 = new Grammar(new GrammarBuilder(\"second grammar\"));  \n        grammar2.Name = \"Grammar2\";  \n        recognizer.LoadGrammar(grammar2);  \n  \n        Grammar grammar3 = new Grammar(new GrammarBuilder(\"third grammar\"));  \n        grammar3.Name = \"Grammar3\";  \n        recognizer.LoadGrammar(grammar3);  \n  \n        // List the recognizer's loaded grammars.  \n        ListGrammars(recognizer);  \n  \n        // Unload one grammar and list the loaded grammars.  \n        Console.WriteLine(\"Unloading Grammar1...\");  \n        recognizer.UnloadGrammar(grammar1);  \n        ListGrammars(recognizer);  \n  \n        // Unload all grammars and list the loaded grammars.  \n        Console.WriteLine(\"Unloading all grammars...\");  \n        recognizer.UnloadAllGrammars();  \n        ListGrammars(recognizer);  \n      }  \n  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    private static void ListGrammars(SpeechRecognitionEngine recognizer)  \n    {  \n      // Make a copy of the recognizer's grammar collection.  \n      List<Grammar> loadedGrammars = new List<Grammar>(recognizer.Grammars);  \n  \n      if (loadedGrammars.Count > 0)  \n      {  \n        Console.WriteLine(\"Loaded grammars:\");  \n        foreach (Grammar g in recognizer.Grammars)  \n        {  \n          Console.WriteLine(\" - {0}\", g.Name);  \n        }  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No grammars loaded.\");  \n      }  \n      Console.WriteLine();  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public void UnloadGrammar (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "Объект грамматики для выгрузки."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>Grammar</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "Грамматика не загружена в данный распознаватель или данный распознаватель загружается грамматики асинхронно."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)
  id: UpdateRecognizerSetting(System.String,System.Int32)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: UpdateRecognizerSetting(String,Int32)
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting(String,Int32)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(String,Int32)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Обновляет указанный параметр для <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> с заданного целого числа."
  remarks: "За исключением элемента `PersistedBackgroundAdaptation`, значения свойств, заданные с помощью метода UpdateRecognizerSetting действуют только для текущего экземпляра <xref:System.Speech.Recognition.SpeechRecognitionEngine>, после которой они вернуться к параметрам по умолчанию.</xref:System.Speech.Recognition.SpeechRecognitionEngine> В разделе <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>Описание поддерживаемых параметров.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>"
  example:
  - "The following example is part of a console application that outputs the values for a number of the settings defined for the recognizer that supports the en-US locale. The example updates the confidence level settings, and then queries the recognizer to check the updated values. The example generates the following output.  \n  \n```  \nSettings for recognizer MS-1033-80-DESK:  \n  \n  ResourceUsage                  is not supported by this recognizer.  \n  ResponseSpeed                  = 150  \n  ComplexResponseSpeed           = 500  \n  AdaptationOn                   = 1  \n  PersistedBackgroundAdaptation  = 1  \n  \nUpdated settings:  \n  \n  ResourceUsage                  is not supported by this recognizer.  \n  ResponseSpeed                  = 200  \n  ComplexResponseSpeed           = 300  \n  AdaptationOn                   = 0  \n  PersistedBackgroundAdaptation  = 0  \n  \nPress any key to exit...  \n```  \n  \n```c#  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace RecognizerSettings  \n{  \n  class Program  \n  {  \n    static readonly string[] settings = new string[] {  \n      \"ResourceUsage\",  \n      \"ResponseSpeed\",  \n      \"ComplexResponseSpeed\",  \n      \"AdaptationOn\",  \n      \"PersistedBackgroundAdaptation\",  \n    };  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        Console.WriteLine(\"Settings for recognizer {0}:\",  \n          recognizer.RecognizerInfo.Name);  \n        Console.WriteLine();  \n  \n        // List the current settings.  \n        ListSettings(recognizer);  \n  \n        // Change some of the settings.  \n        recognizer.UpdateRecognizerSetting(\"ResponseSpeed\", 200);  \n        recognizer.UpdateRecognizerSetting(\"ComplexResponseSpeed\", 300);  \n        recognizer.UpdateRecognizerSetting(\"AdaptationOn\", 1);  \n        recognizer.UpdateRecognizerSetting(\"PersistedBackgroundAdaptation\", 0);  \n  \n        Console.WriteLine(\"Updated settings:\");  \n        Console.WriteLine();  \n  \n        // List the updated settings.  \n        ListSettings(recognizer);  \n      }  \n  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    private static void ListSettings(SpeechRecognitionEngine recognizer)  \n    {  \n      foreach (string setting in settings)  \n      {  \n        try  \n        {  \n          object value = recognizer.QueryRecognizerSetting(setting);  \n          Console.WriteLine(\"  {0,-30} = {1}\", setting, value);  \n        }  \n        catch  \n        {  \n          Console.WriteLine(\"  {0,-30} is not supported by this recognizer.\",  \n            setting);  \n        }  \n      }  \n      Console.WriteLine();  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void UpdateRecognizerSetting (string settingName, int updatedValue);
    parameters:
    - id: settingName
      type: System.String
      description: "Имя параметра для обновления."
    - id: updatedValue
      type: System.Int32
      description: "Новое значение для параметра."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>settingName</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>settingName</code>является пустой строкой (»»)."
  - type: System.Collections.Generic.KeyNotFoundException
    commentId: T:System.Collections.Generic.KeyNotFoundException
    description: "Распознаватель не имеет параметр с таким именем."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)
  id: UpdateRecognizerSetting(System.String,System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: UpdateRecognizerSetting(String,String)
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting(String,String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(String,String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Обновляет параметр механизм распознавания речи указанного указанное строковое значение."
  remarks: "За исключением элемента `PersistedBackgroundAdaptation`, значения свойств, заданные с помощью метода UpdateRecognizerSetting действуют только для текущего экземпляра <xref:System.Speech.Recognition.SpeechRecognitionEngine>, после которой они вернуться к параметрам по умолчанию.</xref:System.Speech.Recognition.SpeechRecognitionEngine> В разделе <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>Описание поддерживаемых параметров.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>"
  syntax:
    content: public void UpdateRecognizerSetting (string settingName, string updatedValue);
    parameters:
    - id: settingName
      type: System.String
      description: "Имя параметра для обновления."
    - id: updatedValue
      type: System.String
      description: "Новое значение для параметра."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>settingName</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>settingName</code>является пустой строкой (»»)."
  - type: System.Collections.Generic.KeyNotFoundException
    commentId: T:System.Collections.Generic.KeyNotFoundException
    description: "Распознаватель не имеет параметр с таким именем."
  platform:
  - net462
references:
- uid: System.Object
  isExternal: false
  name: System.Object
- uid: System.ArgumentException
  isExternal: true
  name: System.ArgumentException
- uid: System.ArgumentNullException
  isExternal: true
  name: System.ArgumentNullException
- uid: System.ArgumentOutOfRangeException
  isExternal: true
  name: System.ArgumentOutOfRangeException
- uid: System.InvalidOperationException
  isExternal: true
  name: System.InvalidOperationException
- uid: System.NotSupportedException
  isExternal: true
  name: System.NotSupportedException
- uid: System.OperationCanceledException
  isExternal: true
  name: System.OperationCanceledException
- uid: System.Collections.Generic.KeyNotFoundException
  isExternal: true
  name: System.Collections.Generic.KeyNotFoundException
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine()
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine(CultureInfo)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(CultureInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(CultureInfo)
- uid: System.Globalization.CultureInfo
  parent: System.Globalization
  isExternal: true
  name: CultureInfo
  nameWithType: CultureInfo
  fullName: System.Globalization.CultureInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine(RecognizerInfo)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(RecognizerInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(RecognizerInfo)
- uid: System.Speech.Recognition.RecognizerInfo
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizerInfo
  nameWithType: RecognizerInfo
  fullName: System.Speech.Recognition.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine(String)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(String)
- uid: System.String
  parent: System
  isExternal: true
  name: String
  nameWithType: String
  fullName: System.String
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioFormat
  nameWithType: SpeechRecognitionEngine.AudioFormat
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
- uid: System.Speech.AudioFormat.SpeechAudioFormatInfo
  parent: System.Speech.AudioFormat
  isExternal: false
  name: SpeechAudioFormatInfo
  nameWithType: SpeechAudioFormatInfo
  fullName: System.Speech.AudioFormat.SpeechAudioFormatInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioLevel
  nameWithType: SpeechRecognitionEngine.AudioLevel
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
- uid: System.Int32
  parent: System
  isExternal: true
  name: Int32
  nameWithType: Int32
  fullName: System.Int32
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioLevelUpdated
  nameWithType: SpeechRecognitionEngine.AudioLevelUpdated
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
- uid: System.EventHandler{System.Speech.Recognition.AudioLevelUpdatedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioLevelUpdatedEventArgs>
  nameWithType: EventHandler<AudioLevelUpdatedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioLevelUpdatedEventArgs
    name: AudioLevelUpdatedEventArgs
    nameWithType: AudioLevelUpdatedEventArgs
    fullName: AudioLevelUpdatedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioPosition
  nameWithType: SpeechRecognitionEngine.AudioPosition
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
- uid: System.TimeSpan
  parent: System
  isExternal: true
  name: TimeSpan
  nameWithType: TimeSpan
  fullName: System.TimeSpan
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioSignalProblemOccurred
  nameWithType: SpeechRecognitionEngine.AudioSignalProblemOccurred
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
- uid: System.EventHandler{System.Speech.Recognition.AudioSignalProblemOccurredEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioSignalProblemOccurredEventArgs>
  nameWithType: EventHandler<AudioSignalProblemOccurredEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioSignalProblemOccurredEventArgs
    name: AudioSignalProblemOccurredEventArgs
    nameWithType: AudioSignalProblemOccurredEventArgs
    fullName: AudioSignalProblemOccurredEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioState
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioState
  nameWithType: SpeechRecognitionEngine.AudioState
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioState
- uid: System.Speech.Recognition.AudioState
  parent: System.Speech.Recognition
  isExternal: false
  name: AudioState
  nameWithType: AudioState
  fullName: System.Speech.Recognition.AudioState
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioStateChanged
  nameWithType: SpeechRecognitionEngine.AudioStateChanged
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
- uid: System.EventHandler{System.Speech.Recognition.AudioStateChangedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioStateChangedEventArgs>
  nameWithType: EventHandler<AudioStateChangedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioStateChangedEventArgs
    name: AudioStateChangedEventArgs
    nameWithType: AudioStateChangedEventArgs
    fullName: AudioStateChangedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: BabbleTimeout
  nameWithType: SpeechRecognitionEngine.BabbleTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Dispose()
  nameWithType: SpeechRecognitionEngine.Dispose()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Dispose()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Dispose(Boolean)
  nameWithType: SpeechRecognitionEngine.Dispose(Boolean)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Dispose(Boolean)
- uid: System.Boolean
  parent: System
  isExternal: true
  name: Boolean
  nameWithType: Boolean
  fullName: System.Boolean
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognize(String)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(String)
- uid: System.Speech.Recognition.RecognitionResult
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognitionResult
  nameWithType: RecognitionResult
  fullName: System.Speech.Recognition.RecognitionResult
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
- uid: System.Speech.Recognition.RecognizedWordUnit[]
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedWordUnit
  nameWithType: RecognizedWordUnit
  fullName: System.Speech.Recognition.RecognizedWordUnit[]
  spec.csharp:
  - uid: System.Speech.Recognition.RecognizedWordUnit
    name: RecognizedWordUnit
    nameWithType: RecognizedWordUnit
    fullName: RecognizedWordUnit[]
  - name: '[]'
    nameWithType: '[]'
    fullName: '[]'
- uid: System.Globalization.CompareOptions
  parent: System.Globalization
  isExternal: true
  name: CompareOptions
  nameWithType: CompareOptions
  fullName: System.Globalization.CompareOptions
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognize(String,CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(String,CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeAsync(String)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(String)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeAsync(String,CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(String,CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeCompleted
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
- uid: System.EventHandler{System.Speech.Recognition.EmulateRecognizeCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<EmulateRecognizeCompletedEventArgs>
  nameWithType: EventHandler<EmulateRecognizeCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.EmulateRecognizeCompletedEventArgs
    name: EmulateRecognizeCompletedEventArgs
    nameWithType: EmulateRecognizeCompletedEventArgs
    fullName: EmulateRecognizeCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EndSilenceTimeout
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EndSilenceTimeoutAmbiguous
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Grammars
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Grammars
  nameWithType: SpeechRecognitionEngine.Grammars
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Grammars
- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.Grammar}
  parent: System.Collections.ObjectModel
  isExternal: true
  name: ReadOnlyCollection<Grammar>
  nameWithType: ReadOnlyCollection<Grammar>
  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.Grammar>
  spec.csharp:
  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1
    name: ReadOnlyCollection
    nameWithType: ReadOnlyCollection
    fullName: ReadOnlyCollection<System.Speech.Recognition.Grammar>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.Grammar
    name: Grammar
    nameWithType: Grammar
    fullName: Grammar
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: InitialSilenceTimeout
  nameWithType: SpeechRecognitionEngine.InitialSilenceTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: InstalledRecognizers()
  nameWithType: SpeechRecognitionEngine.InstalledRecognizers()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers()
- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizerInfo}
  parent: System.Collections.ObjectModel
  isExternal: true
  name: ReadOnlyCollection<RecognizerInfo>
  nameWithType: ReadOnlyCollection<RecognizerInfo>
  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizerInfo>
  spec.csharp:
  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1
    name: ReadOnlyCollection
    nameWithType: ReadOnlyCollection
    fullName: ReadOnlyCollection<System.Speech.Recognition.RecognizerInfo>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizerInfo
    name: RecognizerInfo
    nameWithType: RecognizerInfo
    fullName: RecognizerInfo
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammar(Grammar)
  nameWithType: SpeechRecognitionEngine.LoadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(Grammar)
- uid: System.Speech.Recognition.Grammar
  parent: System.Speech.Recognition
  isExternal: false
  name: Grammar
  nameWithType: Grammar
  fullName: System.Speech.Recognition.Grammar
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammarAsync(Grammar)
  nameWithType: SpeechRecognitionEngine.LoadGrammarAsync(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(Grammar)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammarCompleted
  nameWithType: SpeechRecognitionEngine.LoadGrammarCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
- uid: System.EventHandler{System.Speech.Recognition.LoadGrammarCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<LoadGrammarCompletedEventArgs>
  nameWithType: EventHandler<LoadGrammarCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.LoadGrammarCompletedEventArgs
    name: LoadGrammarCompletedEventArgs
    nameWithType: LoadGrammarCompletedEventArgs
    fullName: LoadGrammarCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: MaxAlternates
  nameWithType: SpeechRecognitionEngine.MaxAlternates
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
- uid: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: QueryRecognizerSetting(String)
  nameWithType: SpeechRecognitionEngine.QueryRecognizerSetting(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(String)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Recognize()
  nameWithType: SpeechRecognitionEngine.Recognize()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Recognize()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Recognize(TimeSpan)
  nameWithType: SpeechRecognitionEngine.Recognize(TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Recognize(TimeSpan)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsync()
  nameWithType: SpeechRecognitionEngine.RecognizeAsync()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsync(RecognizeMode)
  nameWithType: SpeechRecognitionEngine.RecognizeAsync(RecognizeMode)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(RecognizeMode)
- uid: System.Speech.Recognition.RecognizeMode
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizeMode
  nameWithType: RecognizeMode
  fullName: System.Speech.Recognition.RecognizeMode
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsyncCancel()
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncCancel()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsyncStop()
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncStop()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeCompleted
  nameWithType: SpeechRecognitionEngine.RecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
- uid: System.EventHandler{System.Speech.Recognition.RecognizeCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<RecognizeCompletedEventArgs>
  nameWithType: EventHandler<RecognizeCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.RecognizeCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.RecognizeCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizeCompletedEventArgs
    name: RecognizeCompletedEventArgs
    nameWithType: RecognizeCompletedEventArgs
    fullName: RecognizeCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognitionEngine.RecognizerAudioPosition
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerInfo
  nameWithType: SpeechRecognitionEngine.RecognizerInfo
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerUpdateReached
  nameWithType: SpeechRecognitionEngine.RecognizerUpdateReached
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
- uid: System.EventHandler{System.Speech.Recognition.RecognizerUpdateReachedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<RecognizerUpdateReachedEventArgs>
  nameWithType: EventHandler<RecognizerUpdateReachedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizerUpdateReachedEventArgs
    name: RecognizerUpdateReachedEventArgs
    nameWithType: RecognizerUpdateReachedEventArgs
    fullName: RecognizerUpdateReachedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RequestRecognizerUpdate()
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RequestRecognizerUpdate(Object)
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate(Object)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(Object)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RequestRecognizerUpdate(Object,TimeSpan)
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate(Object,TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(Object,TimeSpan)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  nameWithType: SpeechRecognitionEngine.SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
- uid: System.IO.Stream
  parent: System.IO
  isExternal: true
  name: Stream
  nameWithType: Stream
  fullName: System.IO.Stream
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToDefaultAudioDevice()
  nameWithType: SpeechRecognitionEngine.SetInputToDefaultAudioDevice()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToNull()
  nameWithType: SpeechRecognitionEngine.SetInputToNull()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToWaveFile(String)
  nameWithType: SpeechRecognitionEngine.SetInputToWaveFile(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(String)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToWaveStream(Stream)
  nameWithType: SpeechRecognitionEngine.SetInputToWaveStream(Stream)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(Stream)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechDetected
  nameWithType: SpeechRecognitionEngine.SpeechDetected
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
- uid: System.EventHandler{System.Speech.Recognition.SpeechDetectedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechDetectedEventArgs>
  nameWithType: EventHandler<SpeechDetectedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechDetectedEventArgs
    name: SpeechDetectedEventArgs
    nameWithType: SpeechDetectedEventArgs
    fullName: SpeechDetectedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechHypothesized
  nameWithType: SpeechRecognitionEngine.SpeechHypothesized
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
- uid: System.EventHandler{System.Speech.Recognition.SpeechHypothesizedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechHypothesizedEventArgs>
  nameWithType: EventHandler<SpeechHypothesizedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechHypothesizedEventArgs
    name: SpeechHypothesizedEventArgs
    nameWithType: SpeechHypothesizedEventArgs
    fullName: SpeechHypothesizedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionRejected
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionRejected
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
- uid: System.EventHandler{System.Speech.Recognition.SpeechRecognitionRejectedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechRecognitionRejectedEventArgs>
  nameWithType: EventHandler<SpeechRecognitionRejectedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechRecognitionRejectedEventArgs
    name: SpeechRecognitionRejectedEventArgs
    nameWithType: SpeechRecognitionRejectedEventArgs
    fullName: SpeechRecognitionRejectedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognized
  nameWithType: SpeechRecognitionEngine.SpeechRecognized
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
- uid: System.EventHandler{System.Speech.Recognition.SpeechRecognizedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechRecognizedEventArgs>
  nameWithType: EventHandler<SpeechRecognizedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechRecognizedEventArgs
    name: SpeechRecognizedEventArgs
    nameWithType: SpeechRecognizedEventArgs
    fullName: SpeechRecognizedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UnloadAllGrammars()
  nameWithType: SpeechRecognitionEngine.UnloadAllGrammars()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UnloadGrammar(Grammar)
  nameWithType: SpeechRecognitionEngine.UnloadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(Grammar)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UpdateRecognizerSetting(String,Int32)
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting(String,Int32)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(String,Int32)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UpdateRecognizerSetting(String,String)
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting(String,String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(String,String)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioFormat
  nameWithType: SpeechRecognitionEngine.AudioFormat
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioLevel
  nameWithType: SpeechRecognitionEngine.AudioLevel
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioPosition
  nameWithType: SpeechRecognitionEngine.AudioPosition
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioState*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioState
  nameWithType: SpeechRecognitionEngine.AudioState
- uid: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: BabbleTimeout
  nameWithType: SpeechRecognitionEngine.BabbleTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Dispose
  nameWithType: SpeechRecognitionEngine.Dispose
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognize
  nameWithType: SpeechRecognitionEngine.EmulateRecognize
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeAsync
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EndSilenceTimeout
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EndSilenceTimeoutAmbiguous
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Grammars*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Grammars
  nameWithType: SpeechRecognitionEngine.Grammars
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: InitialSilenceTimeout
  nameWithType: SpeechRecognitionEngine.InitialSilenceTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: InstalledRecognizers
  nameWithType: SpeechRecognitionEngine.InstalledRecognizers
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammar
  nameWithType: SpeechRecognitionEngine.LoadGrammar
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammarAsync
  nameWithType: SpeechRecognitionEngine.LoadGrammarAsync
- uid: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: MaxAlternates
  nameWithType: SpeechRecognitionEngine.MaxAlternates
- uid: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: QueryRecognizerSetting
  nameWithType: SpeechRecognitionEngine.QueryRecognizerSetting
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Recognize
  nameWithType: SpeechRecognitionEngine.Recognize
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsync
  nameWithType: SpeechRecognitionEngine.RecognizeAsync
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsyncCancel
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncCancel
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsyncStop
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncStop
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognitionEngine.RecognizerAudioPosition
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerInfo
  nameWithType: SpeechRecognitionEngine.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RequestRecognizerUpdate
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToAudioStream
  nameWithType: SpeechRecognitionEngine.SetInputToAudioStream
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToDefaultAudioDevice
  nameWithType: SpeechRecognitionEngine.SetInputToDefaultAudioDevice
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToNull
  nameWithType: SpeechRecognitionEngine.SetInputToNull
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToWaveFile
  nameWithType: SpeechRecognitionEngine.SetInputToWaveFile
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToWaveStream
  nameWithType: SpeechRecognitionEngine.SetInputToWaveStream
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UnloadAllGrammars
  nameWithType: SpeechRecognitionEngine.UnloadAllGrammars
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UnloadGrammar
  nameWithType: SpeechRecognitionEngine.UnloadGrammar
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UpdateRecognizerSetting
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting
